"""
Rallit Jobs Dashboard - ìŠ¤ë§ˆíŠ¸ ê¸°ëŠ¥ì´ í†µí•©ëœ ìµœì¢… Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜
"""

import streamlit as st
import pandas as pd
import sys
from pathlib import Path
from datetime import datetime, timedelta
import logging
import sqlite3
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import json

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Rallit ìŠ¤ë§ˆíŠ¸ ì±„ìš© ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        margin-bottom: 2rem;
    }
    .problem-card {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        padding: 1.5rem;
        border-radius: 15px;
        color: white;
        margin: 1rem 0;
        box-shadow: 0 8px 32px rgba(31, 38, 135, 0.37);
        min-height: 220px;
    }
    .solution-card {
        background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
        padding: 1.5rem;
        border-radius: 15px;
        color: white;
        margin: 1rem 0;
        box-shadow: 0 8px 32px rgba(31, 38, 135, 0.37);
        min-height: 250px;
    }
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #667eea;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin: 0.5rem 0;
    }
    .skill-match {
        background: #e8f5e8;
        padding: 0.5rem;
        border-radius: 5px;
        border-left: 3px solid #4caf50;
        margin: 0.2rem 0;
    }
    .skill-gap {
        background: #fff3e0;
        padding: 0.5rem;
        border-radius: 5px;
        border-left: 3px solid #ff9800;
        margin: 0.2rem 0;
    }
    .growth-indicator {
        background: linear-gradient(90deg, #a8edea 0%, #fed6e3 100%);
        padding: 0.8rem;
        border-radius: 10px;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)


# AI ê¸°ë°˜ ë§¤ì¹­ ì—”ì§„
class SmartMatchingEngine:
    def __init__(self):
        self.vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)
        
    def calculate_skill_match(self, user_skills, job_requirements):
        """ìŠ¤í‚¬ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
        if not user_skills or not job_requirements or not isinstance(job_requirements, str):
            return 0, [], []

        user_skills_set = set([skill.strip().lower() for skill in user_skills])
        job_skills_set = set([skill.strip().lower() for skill in job_requirements.split(',')])
        
        user_skills_set = {s for s in user_skills_set if s}
        job_skills_set = {s for s in job_skills_set if s}

        if not job_skills_set:
            return 0, [], []

        intersection = user_skills_set.intersection(job_skills_set)
        
        match_score = len(intersection) / len(job_skills_set) * 100
        matched_skills = list(intersection)
        missing_skills = list(job_skills_set - user_skills_set)
        
        return match_score, matched_skills, missing_skills
    
    def analyze_growth_potential(self, user_profile):
        """ì„±ì¥ ì ì¬ë ¥ ë¶„ì„"""
        growth_score = 0
        growth_factors = []
        
        if user_profile.get('recent_courses', 0) > 0:
            growth_score += 20
            growth_factors.append(f"ìµœê·¼ í•™ìŠµ í™œë™ í™œë°œ ({user_profile.get('recent_courses')}ê°œ)")
        if user_profile.get('project_count', 0) > 3:
            growth_score += 25
            growth_factors.append(f"ë‹¤ì–‘í•œ í”„ë¡œì íŠ¸ ê²½í—˜ ({user_profile.get('project_count')}ê°œ)")
        if len(user_profile.get('skills', [])) > 8:
            growth_score += 20
            growth_factors.append(f"ë‹¤ì–‘í•œ ê¸°ìˆ  ìŠ¤íƒ ë³´ìœ  ({len(user_profile.get('skills', []))}ê°œ)")
        if user_profile.get('github_contributions', 0) > 100:
            growth_score += 15
            growth_factors.append(f"í™œë°œí•œ ê°œë°œ ê¸°ì—¬ (ì—° {user_profile.get('github_contributions')}íšŒ)")
        
        modern_skills = ['ai', 'ml', 'docker', 'kubernetes', 'react', 'vue', 'typescript']
        user_skills_lower = [s.lower() for s in user_profile.get('skills', [])]
        if any(skill in user_skills_lower for skill in modern_skills):
            growth_score += 20
            growth_factors.append("ìµœì‹  ê¸°ìˆ  íŠ¸ë Œë“œ ê´€ì‹¬")
        
        return min(growth_score, 100), growth_factors


# ë°ì´í„° ë¡œë” í´ë˜ìŠ¤
class SmartDataLoader:
    def __init__(self, db_path='rallit_jobs.db', data_dir='data'):
        self.db_path = db_path
        self.data_dir = Path(data_dir)
        self.csv_files = {
            'MANAGEMENT': 'rallit_management_jobs.csv',
            'MARKETING': 'rallit_marketing_jobs.csv',
            'DESIGN': 'rallit_design_jobs.csv',
            'DEVELOPER': 'rallit_developer_jobs.csv'
        }
    
    @st.cache_data
    def load_from_database(_self):
        try:
            if not Path(_self.db_path).exists():
                logger.warning(f"Database file {_self.db_path} not found. Creating from CSV.")
                _self._create_database_from_csv()
            conn = sqlite3.connect(_self.db_path)
            df = pd.read_sql_query("SELECT * FROM jobs", conn)
            conn.close()
            logger.info(f"Loaded {len(df)} records from database")
            return df
        except Exception as e:
            logger.error(f"DB loading error: {e}. Falling back to CSV.")
            return _self._load_from_csv_fallback()
    
    def _load_from_csv_fallback(self):
        try:
            all_dfs = []
            for category, filename in self.csv_files.items():
                file_path = self.data_dir / filename
                if file_path.exists():
                    df = pd.read_csv(file_path)
                    df['job_category'] = category
                    all_dfs.append(df)
            if all_dfs:
                combined_df = pd.concat(all_dfs, ignore_index=True)
                # ë°ì´í„° í´ë¦¬ë‹ ë° íƒ€ì… ë³€í™˜
                combined_df.columns = [col.lower().replace(' ', '_') for col in combined_df.columns]
                # ... (í•„ìš” ì‹œ ë” ë§ì€ í´ë¦¬ë‹ ë¡œì§ ì¶”ê°€) ...
                logger.info(f"Combined {len(combined_df)} records from CSVs.")
                return combined_df
            else:
                logger.error("No CSVs found. Loading sample data.")
                return _self._load_sample_data()
        except Exception as e:
            logger.error(f"CSV loading error: {e}. Loading sample data.")
            return _self._load_sample_data()

    def _create_database_from_csv(self):
        df = self._load_from_csv_fallback()
        if not df.empty:
            conn = sqlite3.connect(self.db_path)
            df.to_sql('jobs', conn, if_exists='replace', index=False)
            conn.commit()
            conn.close()
            logger.info("Database created from CSVs.")
    
    def _load_sample_data(self):
        st.warning("ğŸ“ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ìƒ˜í”Œ ë°ì´í„°ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.")
        # ... (ìƒ˜í”Œ ë°ì´í„° ìƒì„± ë¡œì§ì€ ì²«ë²ˆì§¸ ì½”ë“œì—ì„œ ê°€ì ¸ì˜´) ...
        categories = ['DEVELOPER', 'DESIGN', 'MARKETING', 'MANAGEMENT']
        regions = ['PANGYO', 'GANGNAM', 'HONGDAE', 'JONGNO', 'YEOUIDO', 'BUNDANG', 'SEOCHO']
        companies = ['í…Œí¬ì»´í¼ë‹ˆA', 'ìŠ¤íƒ€íŠ¸ì—…B', 'ëŒ€ê¸°ì—…C', 'ì¤‘ê²¬ê¸°ì—…D', 'ë²¤ì²˜E', 'ê¸€ë¡œë²Œê¸°ì—…F', 'AIìŠ¤íƒ€íŠ¸ì—…G']
        skills = {
            'DEVELOPER': ['Python', 'JavaScript', 'React', 'Node.js', 'Java', 'Spring', 'Django', 'Vue.js', 'TypeScript', 'Docker', 'AWS', 'Kubernetes'],
            'DESIGN': ['Figma', 'Sketch', 'Adobe XD', 'Photoshop', 'Illustrator', 'Principle', 'Zeplin', 'InVision', 'Framer'],
            'MARKETING': ['Google Analytics', 'Facebook Ads', 'SEO', 'Content Marketing', 'Social Media', 'Performance Marketing', 'CRM'],
            'MANAGEMENT': ['Project Management', 'Team Leadership', 'Strategic Planning', 'Business Analysis', 'Agile', 'Scrum']
        }
        sample_data = []
        for i in range(200):
            category = random.choice(categories)
            sample_data.append({
                'id': i + 1, 'job_category': category, 'address_region': random.choice(regions),
                'company_id': random.randint(1, 50), 'company_name': random.choice(companies),
                'title': f'{category.title()} ì±„ìš©ê³µê³  - {random.choice(companies)}',
                'status_code': random.choice(['HIRING', 'CLOSED']), 'status_name': random.choice(['ëª¨ì§‘ ì¤‘', 'ë§ˆê°']),
                'is_partner': random.choice([0, 1]), 'is_bookmarked': random.choice([0, 1]),
                'join_reward': random.choice([0, 50000, 100000, 200000, 300000, 500000]),
                'job_skill_keywords': ', '.join(random.sample(skills[category], k=random.randint(3, 6))),
                'job_level': random.choice(['IRRELEVANT', 'JUNIOR', 'SENIOR', 'LEAD']),
                'job_levels': random.choice(['INTERN', 'JUNIOR', 'SENIOR', 'MANAGER']),
                'created_at': datetime.now(), 'company_representative_image': f'https://via.placeholder.com/100x100?text=Logo',
                'url': f'https://www.rallit.com/positions/{i+1}', 'started_at': '2024-01-01', 'ended_at': '2024-12-31'
            })
        return pd.DataFrame(sample_data)

# ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
def main():
    st.markdown('<h1 class="main-header">ğŸš€ Rallit ìŠ¤ë§ˆíŠ¸ ì±„ìš© ëŒ€ì‹œë³´ë“œ</h1>', unsafe_allow_html=True)
    st.markdown("## ğŸ¯ í•´ê²°í•˜ê³ ì í•˜ëŠ” ë¬¸ì œë“¤")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.markdown('<div class="problem-card"><h3>ğŸ‘¤ êµ¬ì§ì ë¬¸ì œ</h3><ul><li>ì í•©í•œ ê³µê³  ì°¾ê¸° ì–´ë ¤ì›€</li><li>JD-ìŠ¤í™ ë¯¸ìŠ¤ë§¤ì¹­</li><li>ì„±ì¥ê³¼ì • í‰ê°€ ë¶€ì¡±</li></ul></div>', unsafe_allow_html=True)
    with col2:
        st.markdown('<div class="problem-card"><h3>ğŸ¢ ê¸°ì—… ë¬¸ì œ</h3><ul><li>ì‹¤ë¬´ì—­ëŸ‰ íŒë‹¨ ì–´ë ¤ì›€</li><li>ì •ëŸ‰ì  ê¸°ì¤€ ë¶€ì¡±</li><li>ì„±ê³¼ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥</li></ul></div>', unsafe_allow_html=True)
    with col3:
        st.markdown('<div class="problem-card"><h3>ğŸ”§ í”Œë«í¼ ë¬¸ì œ</h3><ul><li>ì„±ì¥ì—¬ì • ë¯¸ë°˜ì˜</li><li>ë‹¨ìˆœ í‚¤ì›Œë“œ ë§¤ì¹­</li><li>ìµœì‹  íŠ¸ë Œë“œ ë¶€ì¡±</li></ul></div>', unsafe_allow_html=True)
    st.markdown("---")
    
    # ë°ì´í„° ë¡œë”©
    data_loader = SmartDataLoader()
    matching_engine = SmartMatchingEngine()
    with st.spinner('ë°ì´í„°ë¥¼ ë¡œë”©ì¤‘ì…ë‹ˆë‹¤...'):
        df = data_loader.load_from_database()
    
    if df.empty:
        st.error("ğŸ˜• ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # --- ì‚¬ì´ë“œë°” ---
    st.sidebar.header("ğŸ¯ ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­ í•„í„°")
    st.sidebar.subheader("ğŸ‘¤ ë‹¹ì‹ ì˜ í”„ë¡œí•„")
    user_skills_input = st.sidebar.text_area("ë³´ìœ  ê¸°ìˆ  ìŠ¤íƒ (ì‰¼í‘œë¡œ êµ¬ë¶„)", placeholder="ì˜ˆ: Python, React, AWS")
    job_categories = ['ì „ì²´'] + list(df['job_category'].unique())
    user_category = st.sidebar.selectbox("ê´€ì‹¬ ì§ë¬´", job_categories)
    
    with st.sidebar.expander("ğŸ“ˆ ì„±ì¥ í”„ë¡œí•„ (ì„ íƒ)"):
        recent_courses = st.number_input("ìµœê·¼ 1ë…„ ìˆ˜ê°• ê°•ì˜ ìˆ˜", 0, 50, 0)
        project_count = st.number_input("ê°œì¸/íŒ€ í”„ë¡œì íŠ¸ ìˆ˜", 0, 20, 0)
        github_contributions = st.number_input("GitHub ì—°ê°„ ê¸°ì—¬ë„", 0, 1000, 0)
    
    user_profile = {
        'skills': [s.strip() for s in user_skills_input.split(',') if s.strip()],
        'recent_courses': recent_courses, 'project_count': project_count,
        'github_contributions': github_contributions
    }
    
    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ” ì¼ë°˜ í•„í„°")
    regions = ['ì „ì²´'] + sorted(list(df['address_region'].dropna().unique()))
    selected_region = st.sidebar.selectbox("ê·¼ë¬´ ì§€ì—­", regions)
    reward_filter = st.sidebar.checkbox("ì§€ì›ê¸ˆ ìˆëŠ” ê³µê³ ë§Œ")
    
    if st.sidebar.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"):
        st.cache_data.clear()
        st.rerun()

    filtered_df = df.copy()
    if user_category != 'ì „ì²´': filtered_df = filtered_df[filtered_df['job_category'] == user_category]
    if selected_region != 'ì „ì²´': filtered_df = filtered_df[filtered_df['address_region'] == selected_region]
    if reward_filter: filtered_df = filtered_df[filtered_df['join_reward'] > 0]

    # --- ë©”ì¸ íƒ­ ---
    tabs = st.tabs(["ğŸ¯ ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­", "ğŸ“Š ì‹œì¥ ë¶„ì„", "ğŸ“ˆ ì„±ì¥ ê²½ë¡œ", "ğŸ¢ ê¸°ì—… ì¸ì‚¬ì´íŠ¸", "ğŸ”® ì˜ˆì¸¡ ë¶„ì„", "ğŸ“‹ ìƒì„¸ ë°ì´í„°"])

    with tabs[0]:
        st.header("ğŸ¯ AI ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ Job ë§¤ì¹­")
        if user_skills_input:
            matching_results = []
            for _, job in filtered_df.iterrows():
                match_score, matched, missing = matching_engine.calculate_skill_match(user_profile['skills'], job['job_skill_keywords'])
                if match_score > 20: # ìµœì†Œ ë§¤ì¹­ ì ìˆ˜
                    matching_results.append({'title': job['title'], 'company': job['company_name'], 'score': match_score, 'matched': matched, 'missing': missing})
            matching_results.sort(key=lambda x: x['score'], reverse=True)

            st.subheader("ğŸŒŸ ë§ì¶¤ ì¶”ì²œ ê³µê³ ")
            for i, res in enumerate(matching_results[:5]):
                with st.expander(f"ğŸ† #{i+1} {res['title']} - ë§¤ì¹­ë„: {res['score']:.1f}%"):
                    col1, col2 = st.columns([2, 1])
                    with col1:
                        st.write(f"**íšŒì‚¬:** {res['company']}")
                        if res['matched']: st.markdown("".join([f'<div class="skill-match">âœ… {s}</div>' for s in res['matched']]), unsafe_allow_html=True)
                        if res['missing']: st.markdown("".join([f'<div class="skill-gap">ğŸ“– {s}</div>' for s in res['missing'][:3]]), unsafe_allow_html=True)
                    with col2:
                        fig = go.Figure(go.Indicator(mode="gauge+number", value=res['score'], title={'text': "ë§¤ì¹­ë„"}, gauge={'axis': {'range': [None, 100]}, 'bar': {'color': "#667eea"}}))
                        fig.update_layout(height=200, margin=dict(l=20,r=20,t=40,b=20))
                        st.plotly_chart(fig, use_container_width=True)

            growth_score, factors = matching_engine.analyze_growth_potential(user_profile)
            st.markdown("---"); st.subheader("ğŸ“ˆ ë‹¹ì‹ ì˜ ì„±ì¥ ì ì¬ë ¥")
            col1, col2 = st.columns([1, 2])
            with col1:
                fig = go.Figure(go.Indicator(mode="gauge+number", value=growth_score, title={'text': "ì„±ì¥ ì ì¬ë ¥"}))
                st.plotly_chart(fig, use_container_width=True)
            with col2:
                st.markdown("**ğŸŒ± ì„±ì¥ ìš”ì¸ ë¶„ì„:**")
                for factor in factors: st.markdown(f'<div class="growth-indicator">ğŸŒŸ {factor}</div>', unsafe_allow_html=True)
        else:
            st.info("ğŸ‘† ì‚¬ì´ë“œë°”ì—ì„œ ë³´ìœ  ê¸°ìˆ  ìŠ¤íƒì„ ì…ë ¥í•˜ë©´ ë§ì¶¤ ê³µê³ ë¥¼ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤!")

    with tabs[1]:
        st.header("ğŸ“Š ì±„ìš© ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„")
        col1, col2 = st.columns(2)
        with col1:
            counts = filtered_df['job_category'].value_counts()
            fig = px.pie(values=counts.values, names=counts.index, title="ì§ë¬´ë³„ ê³µê³  ë¶„í¬", hole=0.4)
            st.plotly_chart(fig, use_container_width=True)
        with col2:
            counts = filtered_df['address_region'].value_counts().head(8)
            fig = px.bar(x=counts.values, y=counts.index, orientation='h', title="ìƒìœ„ 8ê°œ ì§€ì—­ ì±„ìš© í˜„í™©")
            st.plotly_chart(fig, use_container_width=True)
        
        st.subheader("ğŸ”¥ ì¸ê¸° ê¸°ìˆ  ìŠ¤íƒ íŠ¸ë Œë“œ")
        skills = filtered_df['job_skill_keywords'].dropna().str.split(',').explode().str.strip()
        skill_counts = skills[skills != ''].value_counts().head(15)
        fig = px.bar(x=skill_counts.values, y=skill_counts.index, orientation='h', title="TOP 15 ì¸ê¸° ê¸°ìˆ ")
        st.plotly_chart(fig, use_container_width=True)

    with tabs[2]:
        st.header("ğŸ“ˆ ê°œì¸ ì„±ì¥ ê²½ë¡œ ë¶„ì„")
        if user_skills_input:
            target_skills = df[df['job_category'] == user_category]['job_skill_keywords'] if user_category != 'ì „ì²´' else df['job_skill_keywords']
            req_skills = target_skills.dropna().str.split(',').explode().str.strip()
            req_counts = req_skills[req_skills != ''].value_counts().head(10)
            
            user_s = [s.lower() for s in user_profile['skills']]
            gap_data = [{'skill': s, 'demand': c, 'status': 'ë³´ìœ ' if s.lower() in user_s else 'í•™ìŠµ í•„ìš”'} for s, c in req_counts.items()]
            gap_df = pd.DataFrame(gap_data)

            fig = px.bar(gap_df, x='demand', y='skill', color='status', orientation='h', title=f"{user_category} í•µì‹¬ ìŠ¤í‚¬ ê°­ ë¶„ì„", color_discrete_map={'ë³´ìœ ': 'green', 'í•™ìŠµ í•„ìš”': 'orange'})
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("ğŸ‘† ì‚¬ì´ë“œë°”ì—ì„œ í”„ë¡œí•„ì„ ì…ë ¥í•˜ë©´ ì„±ì¥ ê²½ë¡œë¥¼ ë¶„ì„í•´ ë“œë¦½ë‹ˆë‹¤!")

    with tabs[3]:
        st.header("ğŸ¢ ê¸°ì—… ì¸ì‚¬ì´íŠ¸")
        top_companies = filtered_df['company_name'].value_counts().head(10)
        st.bar_chart(top_companies, height=400)

    with tabs[4]:
        st.header("ğŸ”® ì˜ˆì¸¡ ë¶„ì„")
        st.info("AI ê¸°ë°˜ ì˜ˆì¸¡ ê¸°ëŠ¥ì€ ê³§ ì¶œì‹œë  ì˜ˆì •ì…ë‹ˆë‹¤. ğŸš€")
        
    with tabs[5]:
        st.header("ğŸ“‹ ì±„ìš© ê³µê³  ìƒì„¸ ì •ë³´")
        st.dataframe(filtered_df, use_container_width=True)
        csv = filtered_df.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“„ CSV ë‹¤ìš´ë¡œë“œ", data=csv, file_name="rallit_jobs.csv")


def show_solutions():
    st.markdown("## ğŸ¯ ìš°ë¦¬ì˜ ì†”ë£¨ì…˜")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.markdown('<div class="solution-card"><h3>ğŸ‘¤ êµ¬ì§ìë¥¼ ìœ„í•œ ì†”ë£¨ì…˜</h3><ul><li>AI ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­</li><li>ê°œì¸í™”ëœ ì„±ì¥ ê²½ë¡œ ì œì•ˆ</li><li>ìŠ¤í‚¬ ê°­ ë¶„ì„ ë° í•™ìŠµ ê°€ì´ë“œ</li><li>ì„±ì¥ ì ì¬ë ¥ ì‹œê°í™”</li></ul></div>', unsafe_allow_html=True)
    with col2:
        st.markdown('<div class="solution-card"><h3>ğŸ¢ ê¸°ì—…ì„ ìœ„í•œ ì†”ë£¨ì…˜</h3><ul><li>í›„ë³´ì ì„±ì¥ íˆìŠ¤í† ë¦¬ ë¶„ì„</li><li>ì±„ìš© ì„±ê³¼ ì˜ˆì¸¡ ëª¨ë¸</li><li>ì‹¤ë¬´ ì—­ëŸ‰ ì •ëŸ‰í™”</li><li>ë¬¸í™” ì í•©ì„± ë¶„ì„</li></ul></div>', unsafe_allow_html=True)
    with col3:
        st.markdown('<div class="solution-card"><h3>ğŸ”§ í”Œë«í¼ í˜ì‹ </h3><ul><li>AI ê¸°ë°˜ ë™ì  ë§¤ì¹­</li><li>ì‹¤ì‹œê°„ ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„</li><li>ê°œì¸í™”ëœ ì¸ì‚¬ì´íŠ¸ ì œê³µ</li><li>ì˜ˆì¸¡ ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ</li></ul></div>', unsafe_allow_html=True)

if __name__ == "__main__":
    try:
        main()
        st.markdown("---")
        show_solutions()
        st.markdown("---")
        st.markdown(
            """
            <div style='text-align: center; padding: 2rem; background: linear-gradient(90deg, #667eea, #764ba2); border-radius: 15px; color: white;'>
                <h3>ğŸš€ Rallit ìŠ¤ë§ˆíŠ¸ ì±„ìš© í”Œë«í¼</h3>
                <p><strong>AIê°€ ì—°ê²°í•˜ëŠ” ì™„ë²½í•œ ë§¤ì¹­, ì„±ì¥ì´ ì¦ëª…í•˜ëŠ” ì§„ì§œ ì—­ëŸ‰</strong></p>
                <p>ğŸ“§ contact@rallit.com | ğŸŒ www.rallit.com | ğŸ“± Rallit Mobile App</p>
            </div>
            """,
            unsafe_allow_html=True
        )
    except Exception as e:
        st.error(f"ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        logger.error(f"Application error: {e}", exc_info=True)
