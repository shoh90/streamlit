# app.py - Rallit ìŠ¤ë§ˆíŠ¸ ì±„ìš© ëŒ€ì‹œë³´ë“œ (ìµœì¢… ì™„ì„±ë³¸, êµ¬ë¬¸ ì˜¤ë¥˜ ìˆ˜ì • ë° ì „ì²´ ê¸°ëŠ¥ í†µí•©)

import streamlit as st
import pandas as pd
import sqlite3
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
from pathlib import Path
import logging
import random
import re
import requests
from bs4 import BeautifulSoup
import folium
from streamlit_folium import st_folium

# ==============================================================================
# 1. í˜ì´ì§€ ë° í™˜ê²½ ì„¤ì •
# ==============================================================================
st.set_page_config(
    page_title="Rallit ìŠ¤ë§ˆíŠ¸ ì±„ìš© ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ==============================================================================
# 2. ì»¤ìŠ¤í…€ CSS
# ==============================================================================
st.markdown("""
<style>
    .kpi-card {
        background-color: #FFFFFF;
        padding: 1rem;
        border-radius: 10px;
        border: 1px solid #E0E0E0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        text-align: center;
        height: 100%;
    }
    .kpi-card h3 {
        font-size: 1rem;
        color: #616161;
        margin-bottom: 0.5rem;
    }
    .kpi-card p {
        font-size: 1.8rem;
        font-weight: bold;
        color: #212121;
        margin: 0;
    }
    .kpi-card small {
        font-size: 0.8rem;
        color: #757575;
    }
    .st-emotion-cache-1g6go59 { /* Streamlit Metricì˜ delta ê°’ì„ ì¡°ì • */
        font-size: 0.9rem !important;
    }
</style>
""", unsafe_allow_html=True)


# ==============================================================================
# 3. í•µì‹¬ í´ë˜ìŠ¤ ì •ì˜
# ==============================================================================
class SmartDataLoader:
    def __init__(self, db_path='rallit_jobs.db', data_dir='data'):
        self.db_path = db_path; self.data_dir = Path(data_dir)
        self.csv_files = {'MANAGEMENT': 'rallit_management_jobs.csv', 'MARKETING': 'rallit_marketing_jobs.csv', 'DESIGN': 'rallit_design_jobs.csv', 'DEVELOPER': 'rallit_developer_jobs.csv'}
    @st.cache_data
    def load_from_database(_self):
        try:
            if not Path(_self.db_path).exists(): _self._create_database_from_csv()
            conn = sqlite3.connect(_self.db_path); df = pd.read_sql_query("SELECT * FROM jobs", conn); conn.close()
            for col in ['join_reward', 'is_partner', 'is_bookmarked']:
                if col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
            if 'created_at' in df.columns: df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')
            return df
        except Exception: return _self._load_from_csv_fallback()
    def _load_from_csv_fallback(self):
        try:
            dfs = [pd.read_csv(self.data_dir / f).assign(job_category=cat) for cat, f in self.csv_files.items() if (self.data_dir / f).exists()]
            if not dfs: return self._load_sample_data()
            df = pd.concat(dfs, ignore_index=True)
            df.columns = [c.lower().replace(' ', '_').replace('.', '_') for c in df.columns]
            for col in ['join_reward', 'is_partner', 'is_bookmarked']:
                if col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
            if 'created_at' not in df.columns: df['created_at'] = datetime.now()
            df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')
            return df
        except Exception: return self._load_sample_data()
    def _create_database_from_csv(self):
        df = self._load_from_csv_fallback()
        if not df.empty: conn = sqlite3.connect(self.db_path); df.to_sql('jobs', conn, if_exists='replace', index=False); conn.close()
    def _load_sample_data(self):
        st.warning("ğŸ“ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ìƒ˜í”Œ ë°ì´í„°ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."); categories = ['DEVELOPER', 'DESIGN', 'MARKETING', 'MANAGEMENT']; regions = ['PANGYO', 'GANGNAM', 'HONGDAE', 'JONGNO']; companies = ['í…Œí¬ì»´í¼ë‹ˆA', 'ìŠ¤íƒ€íŠ¸ì—…B', 'ëŒ€ê¸°ì—…C', 'AIìŠ¤íƒ€íŠ¸ì—…G']; skills = {'DEVELOPER': ['Python', 'JavaScript', 'React', 'Node.js', 'Java', 'Docker', 'AWS'], 'DESIGN': ['Figma', 'Sketch', 'Adobe XD', 'Zeplin'], 'MARKETING': ['Google Analytics', 'SEO', 'Content Marketing'], 'MANAGEMENT': ['Project Management', 'Agile', 'Scrum']}; data = []
        for i in range(200):
            cat = random.choice(categories)
            birth_date = datetime(random.randint(1960, 2002), random.randint(1, 12), random.randint(1, 28))
            age = (datetime.now() - birth_date).days // 365
            data.append({'id': i, 'job_category': cat, 'address_region': random.choice(regions), 'company_name': random.choice(companies), 'title': f'{cat.title()} ì±„ìš© - {random.choice(companies)}', 'status_name': random.choice(['ëª¨ì§‘ ì¤‘', 'ë§ˆê°']), 'status_code': 'HIRING', 'is_partner': random.choice([0, 1]), 'is_bookmarked': 0, 'join_reward': random.choice([0, 50000, 100000, 200000, 500000]), 'job_skill_keywords': ','.join(random.sample(skills[cat], k=random.randint(2, 4))), 'job_level': random.choice(['JUNIOR', 'SENIOR', 'LEAD', 'IRRELEVANT']), 'created_at': datetime.now() - timedelta(days=random.randint(0, 730)), 'gender': random.choice(['ë‚¨ì„±', 'ì—¬ì„±']), 'age': age})
        return pd.DataFrame(data)

class SmartMatchingEngine:
    def calculate_skill_match(self, user_skills, job_requirements):
        if not user_skills or not job_requirements or not isinstance(job_requirements, str): return 0, [], []
        user_skills_set = {s.strip().lower() for s in user_skills if s.strip()}; job_skills_set = {s.strip().lower() for s in job_requirements.split(',') if s.strip()}
        if not job_skills_set: return 0, [], []
        intersection = user_skills_set.intersection(job_skills_set); match_score = (len(intersection) / len(job_skills_set)) * 100 if job_skills_set else 0
        return match_score, list(intersection), list(job_skills_set - user_skills_set)
    def analyze_growth_potential(self, user_profile):
        score, factors = 0, []; modern_skills = ['ai', 'ml', 'docker', 'kubernetes', 'react', 'vue', 'typescript']; user_skills_lower = [s.lower() for s in user_profile.get('skills', [])]
        if user_profile.get('recent_courses', 0) > 0: score += 20; factors.append(f"ìµœê·¼ í•™ìŠµ ({user_profile.get('recent_courses')}ê°œ)")
        if user_profile.get('project_count', 0) > 3: score += 25; factors.append(f"í”„ë¡œì íŠ¸ ê²½í—˜ ({user_profile.get('project_count')}ê°œ)")
        if len(user_profile.get('skills', [])) > 8: score += 20; factors.append(f"ê¸°ìˆ  ìŠ¤íƒ ë‹¤ì–‘ì„± ({len(user_profile.get('skills', []))}ê°œ)")
        if user_profile.get('github_contributions', 0) > 100: score += 15; factors.append(f"ì˜¤í”ˆì†ŒìŠ¤ ê¸°ì—¬ ({user_profile.get('github_contributions')}íšŒ)")
        if any(skill in modern_skills for skill in user_skills_lower): score += 20; factors.append("ìµœì‹  ê¸°ìˆ  íŠ¸ë Œë“œ ê´€ì‹¬")
        return min(score, 100), factors
    def predict_success_probability(self, skill_score, growth_score):
        return round((skill_score * 0.7 + growth_score * 0.3), 1)


# ==============================================================================
# 4. ë·°(View) í•¨ìˆ˜ ì •ì˜
# ==============================================================================
def render_main_summary(df):
    st.header("í•œëˆˆì— ë³´ëŠ” ê³ ìš© í˜„í™©")
    if df.empty:
        st.warning("ìš”ì•½ ì •ë³´ë¥¼ í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 1. KPI ì¹´ë“œ
    c1, c2, c3 = st.columns(3)
    total_insured = len(df)
    with c1: st.markdown(f'<div class="kpi-card"><h3>í”¼ë³´í—˜ì ìˆ˜ (ì „ì²´)</h3><p>{total_insured:,}ëª…</p></div>', unsafe_allow_html=True)
    with c2:
        unemployment_claims = int(total_insured * random.uniform(0.04, 0.05))
        st.markdown(f'<div class="kpi-card"><h3>ì‹¤ì—…ê¸‰ì—¬ ì§€ê¸‰ê±´ìˆ˜ (ìƒ˜í”Œ)</h3><p>{unemployment_claims:,}ê±´</p></div>', unsafe_allow_html=True)
    with c3:
        job_openings = int(total_insured * random.uniform(0.08, 0.12))
        st.markdown(f'<div class="kpi-card"><h3>êµ¬ì¸ê±´ìˆ˜ (ìƒ˜í”Œ)</h3><p>{job_openings:,}ê±´</p></div>', unsafe_allow_html=True)

    st.markdown("---")
    c1, c2 = st.columns([0.6, 0.4])
    with c1:
        st.subheader("ì§€ì—­ë³„ í”¼ë³´í—˜ì ë¶„í¬")
        location_dict = {"ì„œìš¸": [37.5665, 126.9780], "ë¶€ì‚°": [35.1796, 129.0756], "ëŒ€êµ¬": [35.8714, 128.6014], "ì¸ì²œ": [37.4563, 126.7052], "ê´‘ì£¼": [35.1595, 126.8526], "ëŒ€ì „": [36.3504, 127.3845], "ìš¸ì‚°": [35.5384, 129.3114], "ì„¸ì¢…": [36.4801, 127.2891], "ê²½ê¸°": [37.4138, 127.5183], "ê°•ì›": [37.8228, 128.1555], "ì¶©ë¶": [36.6358, 127.4917], "ì¶©ë‚¨": [36.5184, 126.8000], "ì „ë¶": [35.7167, 127.1442], "ì „ë‚¨": [34.8161, 126.4630], "ê²½ë¶": [36.4919, 128.8889], "ê²½ë‚¨": [35.4606, 128.2132], "ì œì£¼": [33.4996, 126.5312], "PANGYO": [37.394776, 127.111195], "GANGNAM": [37.4979, 127.0276], "HONGDAE":[37.5575, 126.9245], "JONGNO":[37.5728, 126.9793]}
        region_counts = df['address_region'].value_counts()
        m = folium.Map(location=[36.5, 127.8], zoom_start=6.5, tiles="cartodbpositron")
        for region, count in region_counts.items():
            if region.upper() in location_dict:
                folium.CircleMarker(location=location_dict[region.upper()], radius=max(5, count / 5), popup=f"{region}: {count}ê±´", color='#3186cc', fill=True, fill_color='#3186cc', fill_opacity=0.6).add_to(m)
        st_folium(m, height=400, use_container_width=True)
    with c2:
        st.subheader("ì‚°ì—…ë³„ í”¼ë³´í—˜ì ë¶„í¬")
        category_counts = df['job_category'].value_counts()
        fig = px.pie(category_counts, values=category_counts.values, names=category_counts.index, title="", hole=0.5)
        fig.update_layout(showlegend=False, margin=dict(l=0, r=0, t=0, b=0), height=400)
        fig.update_traces(textinfo='label+percent', textposition='inside')
        st.plotly_chart(fig, use_container_width=True, config={'displayModeBar': False})
    
    st.markdown("---")
    c1, c2 = st.columns(2)
    with c1:
        st.subheader("ì—°ë ¹ë³„ ë¶„í¬")
        if 'age' in df.columns:
            bins = [0, 29, 39, 49, 59, 100]
            labels = ['29ì„¸ ì´í•˜', '30ëŒ€', '40ëŒ€', '50ëŒ€', '60ì„¸ ì´ìƒ']
            df['age_group'] = pd.cut(df['age'], bins=bins, labels=labels, right=True)
            age_counts = df['age_group'].value_counts().sort_index()
            fig_age = px.bar(age_counts, x=age_counts.index, y=age_counts.values, labels={'x': 'ì—°ë ¹ëŒ€', 'y': 'ì¸ì› ìˆ˜'})
            st.plotly_chart(fig_age, use_container_width=True)
    with c2:
        st.subheader("ì„±ë³„ ë¶„í¬")
        if 'gender' in df.columns:
            gender_counts = df['gender'].value_counts()
            male_pct = gender_counts.get('ë‚¨ì„±', 0) / total_insured * 100
            female_pct = gender_counts.get('ì—¬ì„±', 0) / total_insured * 100
            c2_1, c2_2 = st.columns(2)
            with c2_1: st.markdown(f'<div class="kpi-card"><h3>ë‚¨ì„± ğŸ‘¨â€ğŸ’¼</h3><p>{male_pct:.1f}%</p><small>({gender_counts.get("ë‚¨ì„±", 0):,}ëª…)</small></div>', unsafe_allow_html=True)
            with c2_2: st.markdown(f'<div class="kpi-card"><h3>ì—¬ì„± ğŸ‘©â€ğŸ’¼</h3><p>{female_pct:.1f}%</p><small>({gender_counts.get("ì—¬ì„±", 0):,}ëª…)</small></div>', unsafe_allow_html=True)

def render_smart_matching(filtered_df, user_profile, matching_engine, all_df):
    st.header("ğŸ¯ ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­ ê²°ê³¼")
    if not user_profile['skills']: st.info("ğŸ‘† ì‚¬ì´ë“œë°”ì— ë³´ìœ  ê¸°ìˆ ì„ ì…ë ¥í•˜ë©´ ë§ì¶¤ ê³µê³ ë¥¼ ì¶”ì²œí•´ ë“œë¦½ë‹ˆë‹¤."); return
    growth_score, _ = matching_engine.analyze_growth_potential(user_profile)
    match_results = []
    for idx, row in filtered_df.iterrows():
        skill_score, matched, missing = matching_engine.calculate_skill_match(user_profile['skills'], row.get('job_skill_keywords'))
        if skill_score > 20:
            success_prob = matching_engine.predict_success_probability(skill_score, growth_score)
            match_results.append({'idx': idx, 'title': row['title'], 'company': row['company_name'], 'skill_score': skill_score, 'success_prob': success_prob, 'matched': matched, 'missing': missing})

    st.subheader(f"ğŸŒŸ '{', '.join(user_profile['skills'])}' ìŠ¤í‚¬ê³¼ ë§ëŠ” ì¶”ì²œ ê³µê³ ")
    if not match_results:
        st.warning("ì•„ì‰½ì§€ë§Œ, í˜„ì¬ í•„í„° ì¡°ê±´ì— ë§ëŠ” ì¶”ì²œ ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ë³´ì„¸ìš”.")
        with st.expander("ğŸ¤” í˜¹ì‹œ ì´ëŸ° ê±´ ì–´ë– ì„¸ìš”? (ëŒ€ì•ˆ ì œì•ˆ ê¸°ëŠ¥)"):
            st.markdown("**ë‹¤ë¥¸ ì§ë¬´ ì°¾ì•„ë³´ê¸°**"); current_category = filtered_df['job_category'].iloc[0] if not filtered_df.empty else None
            other_categories = [cat for cat in all_df['job_category'].unique() if cat != current_category]
            if other_categories: st.write(f"í˜„ì¬ ì§ë¬´ ì™¸ì—ë„ ì´ëŸ° ì§ë¬´ë“¤ì´ ìˆìŠµë‹ˆë‹¤: `{'`, `'.join(other_categories[:3])}`")
            st.markdown("**ì¸ì ‘ ê¸°ìˆ  ìŠ¤íƒ í•™ìŠµí•˜ê¸°**"); adjacent_skills = {'React': 'Vue.js', 'Python': 'Go', 'AWS': 'GCP, Azure', 'Docker': 'Kubernetes'}
            suggestions = [f"`{v}`" for k, v in adjacent_skills.items() if k.lower() in [s.lower() for s in user_profile['skills']]]
            if suggestions: st.write(f"í˜„ì¬ ë³´ìœ  ìŠ¤í‚¬ ê¸°ë°˜ìœ¼ë¡œ ì´ëŸ° ê¸°ìˆ ì„ ì¶”ê°€ í•™ìŠµí•˜ë©´ ì¢‹ìŠµë‹ˆë‹¤: {', '.join(suggestions)}")
        return

    for i, res in enumerate(sorted(match_results, key=lambda x: x['success_prob'], reverse=True)[:5]):
        with st.expander(f"ğŸ† #{i+1} {res['title']} - ìµœì¢… í•©ê²© í™•ë¥ : {res['success_prob']}%"):
            c1, c2 = st.columns([2, 1]);
            with c1:
                st.write(f"**íšŒì‚¬:** {res['company']}")
                st.metric(label="JD-ìŠ¤í™ ë§¤ì¹­ë„", value=f"{res['skill_score']:.1f}%")
                if res['matched']: st.markdown("**ğŸ¯ ë³´ìœ  ìŠ¤í‚¬ ë§¤ì¹˜:**" + "".join([f'<div class="skill-match">âœ… {s.capitalize()}</div>' for s in res['matched']]), unsafe_allow_html=True)
                if res['missing']: st.markdown("**ğŸ“š ì¶”ê°€ í•™ìŠµ í•„ìš”:**" + "".join([f'<div class="skill-gap">ğŸ“– {s.capitalize()}</div>' for s in res['missing'][:3]]), unsafe_allow_html=True)
            with c2:
                fig = go.Figure(go.Indicator(mode="gauge+number", value=res['success_prob'], title={'text': "ìµœì¢… í•©ê²© í™•ë¥ "}, domain={'x': [0, 1], 'y': [0, 1]}, gauge={'axis': {'range': [None, 100]}, 'bar': {'color': "#667eea"}}))
                fig.update_layout(height=200, margin=dict(l=20, r=20, t=40, b=20)); st.plotly_chart(fig, use_container_width=True, key=f"match_gauge_{res['idx']}")

def render_market_analysis(filtered_df):
    st.header("ğŸ“Š ì±„ìš© ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„");
    if filtered_df.empty: st.warning("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ì£¼ì„¸ìš”."); return
    c1, c2 = st.columns(2)
    with c1:
        counts = filtered_df['job_category'].value_counts()
        fig = px.pie(counts, values=counts.values, names=counts.index, title="ì§ë¬´ë³„ ê³µê³  ë¶„í¬", hole=0.4)
        st.plotly_chart(fig, use_container_width=True, key="cat_pie_market")
    with c2:
        counts = filtered_df['address_region'].value_counts().head(10)
        fig = px.bar(counts, y=counts.index, x=counts.values, orientation='h', title="ìƒìœ„ 10ê°œ ì§€ì—­ ì±„ìš© í˜„í™©", labels={'y':'ì§€ì—­', 'x':'ê³µê³  ìˆ˜'})
        fig.update_layout(yaxis={'categoryorder':'total ascending'}); st.plotly_chart(fig, use_container_width=True, key="region_bar_market")
    st.subheader("ğŸ”¥ ì¸ê¸° ê¸°ìˆ  ìŠ¤íƒ íŠ¸ë Œë“œ")
    if 'job_skill_keywords' in filtered_df.columns:
        skills = filtered_df['job_skill_keywords'].dropna().str.split(',').explode().str.strip()
        skill_counts = skills[skills != ''].value_counts().head(15)
        if not skill_counts.empty:
            fig = px.bar(skill_counts, x=skill_counts.values, y=skill_counts.index, orientation='h', title="TOP 15 ì¸ê¸° ê¸°ìˆ ", labels={'y':'ê¸°ìˆ ', 'x':'ì–¸ê¸‰ íšŸìˆ˜'})
            fig.update_layout(yaxis={'categoryorder': 'total ascending'}); st.plotly_chart(fig, use_container_width=True, key="skills_bar_market")

def render_growth_path(df, user_profile, user_category, matching_engine):
    st.header("ğŸ“ˆ ê°œì¸ ì„±ì¥ ê²½ë¡œ ë¶„ì„");
    if not user_profile['skills']: st.info("ğŸ‘† ì‚¬ì´ë“œë°”ì— ë³´ìœ  ê¸°ìˆ ì„ ì…ë ¥í•˜ë©´ ì„±ì¥ ê²½ë¡œë¥¼ ë¶„ì„í•´ ë“œë¦½ë‹ˆë‹¤."); return
    st.subheader("ğŸš€ ë‹¹ì‹ ì˜ ì„±ì¥ ì ì¬ë ¥"); growth_score, factors = matching_engine.analyze_growth_potential(user_profile); c1, c2 = st.columns([1, 2])
    with c1: fig = go.Figure(go.Indicator(mode="gauge+number", value=growth_score, title={'text': "ì„±ì¥ ì ì¬ë ¥"})); st.plotly_chart(fig, use_container_width=True, key="growth_gauge_path")
    with c2:
        st.markdown("**ğŸŒ± ì„±ì¥ ìš”ì¸ ë¶„ì„:**");
        if factors: [st.markdown(f'<div class="growth-indicator">{f}</div>', unsafe_allow_html=True) for f in factors]
        else: st.write("ì„±ì¥ í”„ë¡œí•„ì„ ì…ë ¥í•˜ë©´ ë” ì •í™•í•œ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    st.subheader("ğŸ¯ ìŠ¤í‚¬ ê°­ ë¶„ì„")
    if 'job_skill_keywords' in df.columns:
        target_df = df[df['job_category'] == user_category] if user_category != 'ì „ì²´' else df
        req_skills = target_df['job_skill_keywords'].dropna().str.split(',').explode().str.strip()
        req_counts = req_skills[req_skills != ''].value_counts().head(10)
        if not req_counts.empty:
            user_s_lower = [s.lower() for s in user_profile['skills']]
            gap_data = [{'skill': s, 'demand': c, 'status': 'ë³´ìœ ' if s.lower() in user_s_lower else 'í•™ìŠµ í•„ìš”'} for s, c in req_counts.items()]
            fig = px.bar(pd.DataFrame(gap_data), x='demand', y='skill', color='status', orientation='h', title=f"'{user_category}' ì§ë¬´ í•µì‹¬ ìŠ¤í‚¬ê³¼ ë³´ìœ  í˜„í™©", color_discrete_map={'ë³´ìœ ': '#4caf50', 'í•™ìŠµ í•„ìš”': '#ff9800'})
            fig.update_layout(yaxis={'categoryorder': 'total ascending'}); st.plotly_chart(fig, use_container_width=True, key="skill_gap_bar_path")

def render_company_insight(filtered_df):
    st.header("ğŸ¢ ê¸°ì—…ë³„ ì±„ìš© ë¶„ì„");
    if filtered_df.empty: st.warning("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ì£¼ì„¸ìš”."); return
    top_companies = filtered_df['company_name'].value_counts().head(15)
    fig = px.bar(top_companies, y=top_companies.index, x=top_companies.values, orientation='h', title="ì±„ìš© ê³µê³ ê°€ ë§ì€ ê¸°ì—… TOP 15", labels={'y':'ê¸°ì—…ëª…', 'x':'ê³µê³  ìˆ˜'})
    fig.update_layout(yaxis={'categoryorder':'total ascending'}); st.plotly_chart(fig, use_container_width=True, key="company_bar_insight")

@st.cache_data(ttl=3600)
def fetch_employment_report_list():
    base_url = "https://eis.work24.go.kr"
    list_url = f"{base_url}/eisps/opiv/selectOpivList.do"
    try:
        res = requests.get(list_url, timeout=10)
        res.raise_for_status()
        soup = BeautifulSoup(res.text, "html.parser")
        rows = soup.select(".bbs-list tbody tr")
        if not rows: return pd.DataFrame(), "ê²Œì‹œë¬¼ ëª©ë¡(rows)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        report_data = []
        for row in rows[:5]:
            title_cell = row.select_one("td.title")
            if not title_cell or not title_cell.find("a"): continue
            link = title_cell.find("a")
            title = link.text.strip()
            onclick = link.get("onclick")
            if not onclick: continue
            seq_match = re.search(r"fncOpivDetail\('(\d+)'\)", onclick)
            if seq_match:
                seq = seq_match.group(1)
                detail_url = f"https://eis.work24.go.kr/eisps/opiv/selectOpivDetail.do?seq={seq}"
                report_data.append({"ì œëª©": title, "ë§í¬": detail_url})
        if not report_data: return pd.DataFrame(), "íŒŒì‹± ê°€ëŠ¥í•œ ë¦¬í¬íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        return pd.DataFrame(report_data), "SUCCESS"
    except Exception as e: return pd.DataFrame(), f"í¬ë¡¤ë§ ì˜¤ë¥˜: {e}"

def render_employment_report_list_tab():
    st.header("ğŸ“š ê³ ìš©í–‰ì •í†µê³„ ë¦¬í¬íŠ¸ (í¬ë¡¤ë§)")
    df, status = fetch_employment_report_list()
    if status == "SUCCESS" and not df.empty:
        st.dataframe(df, use_container_width=True, hide_index=True,
                     column_config={"ë§í¬": st.column_config.LinkColumn("ìƒì„¸ë³´ê¸°", display_text="ğŸ”— ë°”ë¡œê°€ê¸°")})
    else:
        st.error(f"ë¦¬í¬íŠ¸ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (ìƒíƒœ: {status})")

def render_prediction_analysis():
    st.header("ğŸ”® ì˜ˆì¸¡ ë¶„ì„ (Coming Soon!)")
    st.image("https://images.unsplash.com/photo-1531297484001-80022131f5a1?q=80&w=2020&auto=format&fit=crop", caption="AIê°€ ë‹¹ì‹ ì˜ ì»¤ë¦¬ì–´ ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")
    st.subheader("ì¤€ë¹„ ì¤‘ì¸ ê¸°ëŠ¥ë“¤")
    c1, c2 = st.columns(2)
    with c1:
        st.info("**ğŸ“ˆ ë¯¸ë˜ ì±„ìš© ì‹œì¥ ì˜ˆì¸¡**\n\n- ì§ë¬´ë³„/ê¸°ìˆ ë³„ ì±„ìš© ìˆ˜ìš”ê°€ ì–´ë–»ê²Œ ë³€í• ì§€ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")
        st.info("**ğŸ’° ê°œì¸ ì—°ë´‰ ì˜ˆì¸¡**\n\n- ë‚˜ì˜ ìŠ¤í™ê³¼ ê²½ë ¥ìœ¼ë¡œ ì–´ëŠ ì •ë„ì˜ ì—°ë´‰ì„ ë°›ì„ ìˆ˜ ìˆëŠ”ì§€ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")
    with c2:
        st.info("**ğŸŒ± ê¸°ìˆ  ì„±ì¥ë¥  ì˜ˆì¸¡**\n\n- ì–´ë–¤ ê¸°ìˆ ì´ ë¯¸ë˜ì— ìœ ë§í• ì§€ ì„±ì¥ë¥ ì„ ì˜ˆì¸¡í•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤.")
        st.info("**ğŸ¢ ê¸°ì—… ë¬¸í™” ì í•©ë„ ì˜ˆì¸¡**\n\n- ë‚˜ì˜ ì„±í–¥ê³¼ ê°€ì¥ ì˜ ë§ëŠ” ê¸°ì—… ë¬¸í™”ë¥¼ ì°¾ì•„ ì¶”ì²œí•©ë‹ˆë‹¤.")

def render_detail_table(filtered_df):
    st.header("ğŸ“‹ ìƒì„¸ ë°ì´í„°");
    if filtered_df.empty: st.warning("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ì£¼ì„¸ìš”."); return
    st.dataframe(filtered_df, use_container_width=True, height=600)
    csv = filtered_df.to_csv(index=False).encode('utf-8-sig')
    st.download_button("ğŸ“„ CSV ë‹¤ìš´ë¡œë“œ", csv, "rallit_jobs_filtered.csv", "text/csv")


# ==============================================================================
# 5. ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
# ==============================================================================
def main():
    st.title("Rallit ìŠ¤ë§ˆíŠ¸ ì±„ìš© ëŒ€ì‹œë³´ë“œ")
    
    data_loader = SmartDataLoader(); matching_engine = SmartMatchingEngine(); df = data_loader.load_from_database()
    if df.empty: st.error("ğŸ˜• ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return

    with st.sidebar:
        st.header("ğŸ¯ ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­ í”„ë¡œí•„"); user_skills_input = st.text_area("ë³´ìœ  ê¸°ìˆ  ìŠ¤íƒ (ì‰¼í‘œë¡œ êµ¬ë¶„)", placeholder="ì˜ˆ: Python, React, AWS")
        with st.expander("ğŸ“ˆ ì„±ì¥ í”„ë¡œí•„ (ì„ íƒ)"): recent_courses = st.number_input("ìµœê·¼ 1ë…„ ìˆ˜ê°• ê°•ì˜ ìˆ˜", 0, 50, 0); project_count = st.number_input("ê°œì¸/íŒ€ í”„ë¡œì íŠ¸ ìˆ˜", 0, 20, 0); github_contributions = st.number_input("GitHub ì—°ê°„ ê¸°ì—¬ë„", 0, 1000, 0)
        user_profile = {'skills': [s.strip() for s in user_skills_input.split(',') if s.strip()], 'recent_courses': recent_courses, 'project_count': project_count, 'github_contributions': github_contributions}
        
        st.markdown("---"); st.header("ğŸ” ê³ ê¸‰ í•„í„°"); user_category = st.selectbox("ê´€ì‹¬ ì§ë¬´", ['ì „ì²´'] + sorted(list(df['job_category'].dropna().unique()))); selected_region = st.selectbox("ğŸ“ ê·¼ë¬´ ì§€ì—­", ['ì „ì²´'] + sorted(list(df['address_region'].dropna().unique())))
        reward_filter = st.checkbox("ğŸ’° ì§€ì›ê¸ˆ ìˆëŠ” ê³µê³ ë§Œ ë³´ê¸°"); partner_filter = st.checkbox("ğŸ¤ íŒŒíŠ¸ë„ˆ ê¸°ì—…ë§Œ ë³´ê¸°")
        min_r, max_r = int(df['join_reward'].min()), int(df['join_reward'].max()); join_reward_range = st.slider("ğŸ’µ ì§€ì›ê¸ˆ ë²”ìœ„ (ì›)", min_r, max_r, (min_r, max_r))
        selected_levels = st.multiselect("ğŸ“ˆ ì§ë¬´ ë ˆë²¨", df['job_level'].dropna().unique(), default=list(df['job_level'].dropna().unique())); keyword_input = st.text_input("ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰ (ê³µê³ ëª…/íšŒì‚¬ëª…)", "")
        if st.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"): st.cache_data.clear(); st.rerun()

    filtered_df = df.copy()
    if user_category != 'ì „ì²´': filtered_df = filtered_df[filtered_df['job_category'] == user_category]
    if selected_region != 'ì „ì²´': filtered_df = filtered_df[filtered_df['address_region'] == selected_region]
    if reward_filter: filtered_df = filtered_df[filtered_df['join_reward'] > 0]
    if partner_filter: filtered_df = filtered_df[filtered_df['is_partner'] == 1]
    if selected_levels: filtered_df = filtered_df[filtered_df['job_level'].isin(selected_levels)]
    filtered_df = filtered_df[filtered_df['join_reward'].between(join_reward_range[0], join_reward_range[1])]
    if keyword_input:
        keyword = keyword_input.lower()
        mask = (filtered_df['title'].str.lower().str.contains(keyword, na=False)) | (filtered_df['company_name'].str.lower().str.contains(keyword, na=False))
        filtered_df = filtered_df[mask]
    if user_profile['skills'] and 'job_skill_keywords' in filtered_df.columns:
        user_skills_pattern = '|'.join([re.escape(skill.strip()) for skill in user_profile['skills']])
        filtered_df = filtered_df[filtered_df['job_skill_keywords'].str.contains(user_skills_pattern, case=False, na=False)]

    summary_list = [f"**ë³´ìœ  ìŠ¤í‚¬:** `{', '.join(user_profile['skills'])}`" if user_profile['skills'] else '', f"**ì§ë¬´:** `{user_category}`" if user_category != 'ì „ì²´' else '', f"**ì§€ì—­:** `{selected_region}`" if selected_region != 'ì „ì²´' else '', f"**í‚¤ì›Œë“œ:** `{keyword_input}`" if keyword_input else '']
    active_filters = " | ".join(filter(None, summary_list))
    st.success(f"ğŸ” **í•„í„° ìš”ì•½:** {active_filters if active_filters else 'ì „ì²´ ì¡°ê±´'} | **ê²°ê³¼:** `{len(filtered_df)}`ê°œì˜ ê³µê³ ")

    tabs = st.tabs(["â­ ë©”ì¸ ìš”ì•½", "ğŸ¯ ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­", "ğŸ“Š ì‹œì¥ ë¶„ì„", "ğŸ’¡ ë…¸ë™ì‹œì¥ ë™í–¥", "ğŸ“ˆ ì„±ì¥ ê²½ë¡œ", "ğŸ¢ ê¸°ì—… ì¸ì‚¬ì´íŠ¸", "ğŸ”® ì˜ˆì¸¡ ë¶„ì„", "ğŸ“‹ ìƒì„¸ ë°ì´í„°"])
    with tabs[0]: render_main_summary(df)
    with tabs[1]: render_smart_matching(filtered_df, user_profile, matching_engine, df)
    with tabs[2]: render_market_analysis(filtered_df)
    with tabs[3]: render_employment_report_list()
    with tabs[4]: render_growth_path(df, user_profile, user_category, matching_engine)
    with tabs[5]: render_company_insight(filtered_df)
    with tabs[6]: render_prediction_analysis()
    with tabs[7]: render_detail_table(filtered_df)

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        st.error(f"ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"); logger.error(f"Application error: {e}", exc_info=True)
