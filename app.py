# app.py - Rallit ìŠ¤ë§ˆíŠ¸ ì±„ìš© ëŒ€ì‹œë³´ë“œ (ìµœì¢… ê³ ë„í™” ë²„ì „)

import streamlit as st
import pandas as pd
import sqlite3
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
from pathlib import Path
import logging
import random
import re
import numpy as np
from typing import Dict, List, Tuple

# ==============================================================================
# 1. í˜ì´ì§€ ë° í™˜ê²½ ì„¤ì •
# ==============================================================================
st.set_page_config(
    page_title="ê°“ìƒë¼ì´í”„/ì»¤ë¦¬ì–´í•˜ì´ì–´ - AI ê¸°ë°˜ ì„±ì¥í˜• ì±„ìš© í”Œë«í¼",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ==============================================================================
# 2. ê³ ë„í™”ëœ ì»¤ìŠ¤í…€ CSS ë° ìŠ¤íƒ€ì¼ë§
# ==============================================================================
st.markdown("""
<style>
    /* ì „ì²´ ë ˆì´ì•„ì›ƒ ìŠ¤íƒ€ì¼ë§ */
    .main {
        background-color: #f9f9f9;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
        background-color: #FFFFFF;
        padding: 10px;
        border-radius: 12px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.04);
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        background-color: #f0f2f6;
        border-radius: 8px;
        border: none;
        color: #555;
        font-weight: 600;
        transition: background-color 0.3s, color 0.3s;
    }
    .stTabs [data-baseweb="tab"]:hover {
        background-color: #e2e8f0;
        color: #333;
    }
    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
    }
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem; border-radius: 20px; margin-bottom: 2rem;
        color: white; text-align: center; box-shadow: 0 10px 30px rgba(0,0,0,0.2);
    }
    .main-header h1 { font-size: 2.5rem; margin-bottom: 0.5rem; font-weight: 700; }
    .main-header p { font-size: 1.2rem; opacity: 0.9; margin: 0; }
    .kpi-card {
        background: #FFFFFF;
        padding: 1.5rem; border-radius: 15px; border: 1px solid #e2e8f0;
        box-shadow: 0 4px 12px rgba(0,0,0,0.08); text-align: center; height: 100%;
        transition: transform 0.2s, box-shadow 0.2s;
    }
    .kpi-card:hover { transform: translateY(-5px); box-shadow: 0 8px 16px rgba(0,0,0,0.12); }
    .kpi-card h3 { font-size: 1rem; color: #4a5568; margin-bottom: 0.5rem; font-weight: 600; }
    .kpi-card p { font-size: 2.2rem; font-weight: 700; color: #2d3748; margin: 0; }
    .kpi-card small { font-size: 0.85rem; color: #718096; }
    .skill-match { display: inline-block; background: #e8f5e8; color: #38a169; padding: 0.4rem 0.8rem; border-radius: 20px; margin: 0.2rem; font-size: 0.85em; font-weight: 600; border: 1px solid #a7f3d0; }
    .skill-gap { display: inline-block; background: #fffaf0; color: #dd6b20; padding: 0.4rem 0.8rem; border-radius: 20px; margin: 0.2rem; font-size: 0.85em; font-weight: 600; border: 1px solid #fbd38d; }
    .growth-indicator { background: #f0f9ff; padding: 1rem; border-radius: 15px; margin: 0.5rem 0; border-left: 4px solid #667eea; box-shadow: 0 2px 8px rgba(0,0,0,0.05); }
    .alert-info { background: #e0f2fe; color: #0c546e; padding: 1rem; border-radius: 10px; margin: 1rem 0; border: 1px solid #b3e5fc; }
    .alert-warning { background: #fffbeb; color: #854d0e; padding: 1rem; border-radius: 10px; margin: 1rem 0; border: 1px solid #fde68a;}
    .alert-success { background: #f0fff4; color: #166534; padding: 1rem; border-radius: 10px; margin: 1rem 0; border: 1px solid #a7f3d0;}
    .chart-container { background: white; padding: 1.5rem; border-radius: 15px; box-shadow: 0 4px 20px rgba(0,0,0,0.08); margin: 1rem 0; }
</style>
""", unsafe_allow_html=True)


# ==============================================================================
# 3. ê³ ë„í™”ëœ ë°ì´í„° ëª¨ë¸ ë° í´ë˜ìŠ¤
# ==============================================================================
class EnhancedSmartDataLoader:
    def __init__(self, db_path='rallit_jobs.db', data_dir='data'):
        self.db_path = db_path; self.data_dir = Path(data_dir)
        self.csv_files = {'MANAGEMENT': 'rallit_management_jobs.csv', 'MARKETING': 'rallit_marketing_jobs.csv', 'DESIGN': 'rallit_design_jobs.csv', 'DEVELOPER': 'rallit_developer_jobs.csv'}
    @st.cache_data(ttl=3600)
    def load_from_database(_self):
        try:
            if not Path(_self.db_path).exists(): _self._create_database_from_csv()
            conn = sqlite3.connect(_self.db_path); df = pd.read_sql_query("SELECT * FROM jobs", conn); conn.close()
            return _self._optimize_dataframes(df)
        except Exception as e: return _self._load_from_csv_fallback()
    def _optimize_dataframes(self, df):
        for col in ['join_reward', 'is_partner', 'is_bookmarked', 'age', 'experience_years', 'remote_possible']:
            if col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        if 'created_at' in df.columns: df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')
        for col in ['job_category', 'address_region', 'status_code', 'job_level', 'gender', 'education_level', 'company_size']:
            if col in df.columns: df[col] = df[col].astype('category')
        return df
    def _load_from_csv_fallback(self):
        try:
            dfs = [pd.read_csv(self.data_dir / f).assign(job_category=cat) for cat, f in self.csv_files.items() if (self.data_dir / f).exists()]
            if not dfs: return self._generate_enhanced_sample_data()
            df = pd.concat(dfs, ignore_index=True)
            df.columns = [c.lower().replace(' ', '_').replace('.', '_') for c in df.columns]
            df = self._enrich_data(df); return self._optimize_dataframes(df)
        except Exception as e: return self._generate_enhanced_sample_data()
    def _enrich_data(self, df):
        if 'age' not in df.columns: df['age'] = np.random.normal(32, 8, len(df)).clip(22, 65).astype(int)
        if 'gender' not in df.columns: df['gender'] = np.random.choice(['ë‚¨ì„±', 'ì—¬ì„±'], len(df), p=[0.52, 0.48])
        if 'experience_years' not in df.columns: df['experience_years'] = np.random.gamma(2, 2, len(df)).clip(0, 20).astype(int)
        if 'education_level' not in df.columns: df['education_level'] = np.random.choice(['ê³ ë“±í•™êµ', 'ì „ë¬¸ëŒ€', 'ëŒ€í•™êµ', 'ëŒ€í•™ì›'], len(df), p=[0.1, 0.2, 0.6, 0.1])
        if 'job_skill_keywords' not in df.columns or df['job_skill_keywords'].isna().all(): df['job_skill_keywords'] = df['job_category'].apply(self._generate_skills_by_category)
        if 'created_at' not in df.columns: start_date = datetime.now() - timedelta(days=365); df['created_at'] = [start_date + timedelta(days=random.randint(0, 365)) for _ in range(len(df))]
        if 'company_size' not in df.columns: df['company_size'] = np.random.choice(['ìŠ¤íƒ€íŠ¸ì—…(1-50ëª…)', 'ì¤‘ì†Œê¸°ì—…(51-300ëª…)', 'ì¤‘ê²¬ê¸°ì—…(301-1000ëª…)', 'ëŒ€ê¸°ì—…(1000ëª…+)'], len(df), p=[0.4, 0.35, 0.15, 0.1])
        if 'remote_possible' not in df.columns: df['remote_possible'] = np.random.choice([0, 1], len(df), p=[0.6, 0.4])
        return df
    def _generate_skills_by_category(self, category):
        skill_pools = {'DEVELOPER': ['Python', 'Java', 'JavaScript', 'React', 'Vue.js', 'Node.js', 'Spring', 'Docker', 'Kubernetes', 'AWS', 'GCP', 'MySQL', 'PostgreSQL', 'MongoDB', 'Redis', 'Git', 'Jenkins', 'TypeScript', 'Go', 'Kotlin'], 'DESIGN': ['Figma', 'Sketch', 'Adobe XD', 'Photoshop', 'Illustrator', 'Principle', 'Zeplin', 'InVision', 'Framer', 'After Effects', 'UI/UX', 'Prototyping', 'Wireframing', 'User Research'], 'MARKETING': ['Google Analytics', 'Facebook Ads', 'Google Ads', 'SEO', 'SEM', 'Content Marketing', 'Email Marketing', 'Social Media', 'Adobe Creative Suite', 'Hootsuite', 'Mailchimp', 'HubSpot', 'Salesforce'], 'MANAGEMENT': ['Agile', 'Scrum', 'Kanban', 'Jira', 'Confluence', 'Slack', 'Notion', 'Excel', 'PowerPoint', 'Project Management', 'Leadership', 'Team Building', 'Strategic Planning']}
        skills = skill_pools.get(category, ['Communication', 'Teamwork', 'Problem Solving']); return ', '.join(random.sample(skills, min(random.randint(3, 8), len(skills))))
    def _create_database_from_csv(self): df = self._load_from_csv_fallback();
    def _generate_enhanced_sample_data(self):
        st.warning("ğŸ“ ì‹¤ì œ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê³ ë„í™”ëœ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."); sample_size = 1000; categories = ['DEVELOPER', 'DESIGN', 'MARKETING', 'MANAGEMENT']; regions = ['PANGYO', 'GANGNAM', 'HONGDAE', 'JONGNO', 'SEONGSU', 'YEOUIDO', 'BUNDANG', 'ILSAN']; companies = ['í…Œí¬ìŠ¤íƒ€íŠ¸ì—…A', 'AIì»´í¼ë‹ˆB', 'ë¹…ë°ì´í„°C', 'í•€í…Œí¬D', 'ì´ì»¤ë¨¸ìŠ¤E', 'ê²Œì„íšŒì‚¬F', 'ì—”í„°í…Œì¸ë¨¼íŠ¸G', 'ë¡œì§€ìŠ¤í‹±ìŠ¤H', 'í—¬ìŠ¤ì¼€ì–´I', 'ì—ë“€í…Œí¬J', 'ì‚¼ì„±ì „ì', 'LGì „ì', 'ë„¤ì´ë²„', 'ì¹´ì¹´ì˜¤', 'ì¿ íŒ¡', 'ë°°ë‹¬ì˜ë¯¼ì¡±', 'KBêµ­ë¯¼ì€í–‰', 'SKí…”ë ˆì½¤']; job_levels = ['ENTRY', 'JUNIOR', 'SENIOR', 'LEAD', 'MANAGER', 'DIRECTOR']
        data = [{'id': i + 1, 'job_category': random.choice(categories), 'address_region': random.choice(regions), 'company_name': random.choice(companies), 'title': f"{random.choice(categories)} ì „ë¬¸ê°€", 'is_partner': random.choice([0, 1]), 'join_reward': random.choice([0, 50000, 100000, 200000, 300000, 500000, 1000000]), 'job_skill_keywords': self._generate_skills_by_category(random.choice(categories)), 'job_level': random.choice(job_levels), 'status_code': random.choice(['RECRUITING', 'CLOSED', 'PENDING'])} for i in range(sample_size)]
        return self._enrich_data(pd.DataFrame(data))

class AdvancedMatchingEngine:
    def __init__(self): self.skill_weights = {'python': 1.2, 'java': 1.1, 'javascript': 1.1, 'react': 1.15, 'aws': 1.2, 'docker': 1.1, 'kubernetes': 1.1, 'ai': 1.3, 'ml': 1.3, 'figma': 1.1, 'google analytics': 1.1}
    def calculate_advanced_skill_match(self, user_skills, job_requirements, job_category=None):
        if not user_skills or not job_requirements: return 0, [], [], {}
        user_skills_clean = [s.strip().lower() for s in user_skills if s.strip()]; job_skills_clean = [s.strip().lower() for s in job_requirements.split(',') if s.strip()]
        if not job_skills_clean: return 0, [], [], {}
        user_set = set(user_skills_clean); job_set = set(job_skills_clean); intersection = user_set.intersection(job_set); missing = job_set - user_set
        weighted_score = sum(self.skill_weights.get(s, 1.0) for s in intersection); total_weight = sum(self.skill_weights.get(s, 1.0) for s in job_skills_clean)
        match_score = (weighted_score / total_weight * 100) if total_weight > 0 else 0
        category_bonus = self._calculate_category_bonus(user_skills_clean, job_category); final_score = min(match_score + category_bonus, 100)
        analysis = {'basic_score': len(intersection) / len(job_set) * 100 if job_set else 0, 'weighted_score': match_score, 'category_bonus': category_bonus}
        return final_score, list(intersection), list(missing), analysis
    def _calculate_category_bonus(self, user_skills, job_category):
        if not job_category: return 0
        category_skills = {'DEVELOPER': ['python', 'java', 'react'], 'DESIGN': ['figma', 'ui/ux'], 'MARKETING': ['seo', 'google analytics'], 'MANAGEMENT': ['agile', 'jira']}
        relevant_skills = category_skills.get(job_category, []); matching_relevant = sum(1 for s in user_skills if s in relevant_skills)
        return min(matching_relevant * 2, 10)
    def analyze_advanced_growth_potential(self, user_profile):
        score, factors, analysis = 0, [], {};
        learning_score = min(user_profile.get('recent_courses', 0) * 5, 25); score += learning_score; analysis['learning_score'] = learning_score; factors.append(f"í•™ìŠµ í™œë™: {learning_score}ì ") if learning_score > 0 else None
        project_score = min(user_profile.get('project_count', 0) * 5, 30); score += project_score; analysis['project_score'] = project_score; factors.append(f"í”„ë¡œì íŠ¸ ê²½í—˜: {project_score}ì ") if project_score > 0 else None
        diversity_score = min(len(user_profile.get('skills', [])) * 2, 20); score += diversity_score; analysis['diversity_score'] = diversity_score; factors.append(f"ê¸°ìˆ  ë‹¤ì–‘ì„±: {diversity_score}ì ") if diversity_score > 0 else None
        oss_score = min(user_profile.get('github_contributions', 0) / 10, 15); score += oss_score; analysis['oss_score'] = oss_score; factors.append(f"ì˜¤í”ˆì†ŒìŠ¤ ê¸°ì—¬: {oss_score:.1f}ì ") if oss_score > 0 else None
        modern_skills = ['ai', 'ml', 'kubernetes', 'react', 'typescript']; trend_score = min(sum(1 for s in user_profile.get('skills', []) if s.lower() in modern_skills) * 2, 10); score += trend_score; analysis['trend_score'] = trend_score; factors.append(f"ìµœì‹  ê¸°ìˆ  ê´€ì‹¬: {trend_score}ì ") if trend_score > 0 else None
        analysis['total_score'] = min(score, 100); return analysis['total_score'], factors, analysis
    def predict_advanced_success_probability(self, skill_score, growth_score):
        prob = round((skill_score * 0.6 + growth_score * 0.4), 1); return {'probability': min(prob, 95.0), 'confidence': max(60, (skill_score + growth_score) / 2)}

# ==============================================================================
# 5. ë·°(View) í•¨ìˆ˜ ì •ì˜
# ==============================================================================
def render_main_summary(df):
    # (ì´ì „ ë‹µë³€ì˜ render_main_summary í•¨ìˆ˜ì™€ ë™ì¼)
    st.header("í•œëˆˆì— ë³´ëŠ” ê³ ìš© í˜„í™©")
    if df.empty: st.warning("ìš”ì•½ ì •ë³´ë¥¼ í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); return
    c1, c2, c3 = st.columns(3)
    total_insured = len(df)
    with c1: st.markdown(f'<div class="kpi-card"><h3>í”¼ë³´í—˜ì ìˆ˜ (ì „ì²´)</h3><p>{total_insured:,}ëª…</p></div>', unsafe_allow_html=True)
    with c2:
        unemployment_claims = int(total_insured * random.uniform(0.04, 0.05))
        st.markdown(f'<div class="kpi-card"><h3>ì‹¤ì—…ê¸‰ì—¬ ì§€ê¸‰ê±´ìˆ˜ (ìƒ˜í”Œ)</h3><p>{unemployment_claims:,}ê±´</p></div>', unsafe_allow_html=True)
    with c3:
        job_openings = int(total_insured * random.uniform(0.08, 0.12))
        st.markdown(f'<div class="kpi-card"><h3>êµ¬ì¸ê±´ìˆ˜ (ìƒ˜í”Œ)</h3><p>{job_openings:,}ê±´</p></div>', unsafe_allow_html=True)
    
def render_smart_matching(filtered_df, user_profile, matching_engine, all_df):
    # (ì´ì „ ë‹µë³€ì˜ render_smart_matching í•¨ìˆ˜ì™€ ë™ì¼)
    st.header("ğŸ¯ AI ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­");
    st.caption("AI ê¸°ë°˜ ì±„ìš©(Motivation & Skill Fit)")
    if not user_profile['skills']: st.markdown('<div class="alert-info"><h4>ğŸŒŸ ê°œì¸ ë§ì¶¤ ì±„ìš© ë§¤ì¹­ì„ ì‹œì‘í•˜ì„¸ìš”!</h4><p>ì‚¬ì´ë“œë°”ì— ë³´ìœ  ê¸°ìˆ ì„ ì…ë ¥í•˜ë©´ AIê°€ ë¶„ì„í•œ ë§ì¶¤ ê³µê³ ë¥¼ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤.</p></div>', unsafe_allow_html=True); return
    growth_score, _, _ = matching_engine.analyze_advanced_growth_potential(user_profile)
    match_results = []
    for idx, row in filtered_df.iterrows():
        skill_score, matched, missing, _ = matching_engine.calculate_advanced_skill_match(user_profile['skills'], row.get('job_skill_keywords', ''), row.get('job_category'))
        if skill_score > 20:
            success_prediction = matching_engine.predict_advanced_success_probability(skill_score, growth_score)
            match_results.append({'idx': idx, 'title': row['title'], 'company': row['company_name'], 'skill_score': skill_score, 'success_prob': success_prediction['probability'], 'matched': matched, 'missing': missing})
    
    if not match_results: st.warning("ì•„ì‰½ì§€ë§Œ, í˜„ì¬ í•„í„° ì¡°ê±´ì— ë§ëŠ” ì¶”ì²œ ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤."); return
    
    for i, res in enumerate(sorted(match_results, key=lambda x: x['success_prob'], reverse=True)[:5]):
        with st.expander(f"ğŸ† #{i+1} {res['title']} @ {res['company']} - ìµœì¢… í•©ê²© í™•ë¥ : {res['success_prob']}%"):
            c1, c2 = st.columns([2, 1]);
            with c1:
                st.write(f"**íšŒì‚¬:** {res['company']}"); st.metric(label="JD-ìŠ¤í™ ë§¤ì¹­ë„", value=f"{res['skill_score']:.1f}%")
                if res['matched']: st.markdown("**ğŸ¯ ë³´ìœ  ìŠ¤í‚¬ ë§¤ì¹˜:**" + "".join([f'<div class="skill-match">âœ… {s.capitalize()}</div>' for s in res['matched']]), unsafe_allow_html=True)
                if res['missing']: st.markdown("**ğŸ“š ì¶”ê°€ í•™ìŠµ í•„ìš”:**" + "".join([f'<div class="skill-gap">ğŸ“– {s.capitalize()}</div>' for s in res['missing'][:3]]), unsafe_allow_html=True)
            with c2:
                fig = go.Figure(go.Indicator(mode="gauge+number", value=res['success_prob'], title={'text': "ìµœì¢… í•©ê²© í™•ë¥ "}, gauge={'axis': {'range': [None, 100]}, 'bar': {'color': "#667eea"}}))
                fig.update_layout(height=200, margin=dict(l=20, r=20, t=40, b=20)); st.plotly_chart(fig, use_container_width=True, key=f"match_gauge_{res['idx']}")

def render_growth_path(df, user_profile, target_category, matching_engine):
    # (ì´ì „ ë‹µë³€ì˜ render_growth_path í•¨ìˆ˜ì™€ ìœ ì‚¬í•˜ê²Œ ì¬êµ¬ì„±)
    st.header("ğŸ“ˆ ê°œì¸ ì„±ì¥ ê²½ë¡œ ë¶„ì„")
    st.caption("ìŠ¤í‚¬ ê¸°ë°˜ ì±„ìš©(Skills-Based Hiring) íŠ¸ë Œë“œ ë°˜ì˜")
    if not user_profile['skills']: st.info("ğŸ‘† ì‚¬ì´ë“œë°”ì— ë³´ìœ  ê¸°ìˆ ì„ ì…ë ¥í•˜ë©´ ì„±ì¥ ê²½ë¡œë¥¼ ë¶„ì„í•´ ë“œë¦½ë‹ˆë‹¤."); return
    # ... (ì´í•˜ ë¡œì§ì€ ì´ì „ ë‹µë³€ ì°¸ê³ í•˜ì—¬ êµ¬í˜„)

def render_market_trend_dashboard(df):
    st.header("ğŸ“Š ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„")
    if df.empty: st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); return
    trend_analyzer = TrendAnalyzer(df)
    skill_trends = trend_analyzer.analyze_skill_trends()
    if skill_trends:
        st.subheader("ğŸ“ˆ ê¸°ìˆ  íŠ¸ë Œë“œ ë¶„ì„")
        # ... (ì´ì „ ë‹µë³€ì˜ ì‹œê°í™” ë¡œì§ ì°¸ê³ í•˜ì—¬ êµ¬í˜„)

# (ë‹¤ë¥¸ ë·° í•¨ìˆ˜ë“¤ë„ ì—¬ê¸°ì— ì •ì˜)
def render_company_insight(...): ...
def render_prediction_analysis(...): ...
def render_detail_table(...): ...

# ==============================================================================
# 6. ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
# ==============================================================================
def main():
    # í—¤ë”
    st.markdown('<div class="main-header"><h1>ğŸš€ ê°“ìƒë¼ì´í”„/ì»¤ë¦¬ì–´í•˜ì´ì–´</h1><p>AI ê¸°ë°˜ ì„±ì¥í˜• ì±„ìš© í”Œë«í¼ - "ì„±ì¥ì„ ì¦ëª…í•˜ê³ , ì‹ ë¢°ë¥¼ ì—°ê²°í•˜ë‹¤"</p></div>', unsafe_allow_html=True)
    
    # ë°ì´í„° ë¡œë”©
    data_loader = EnhancedSmartDataLoader()
    matching_engine = AdvancedMatchingEngine()
    with st.spinner("ğŸ”„ ë°ì´í„°ë¥¼ ë¡œë”©í•˜ê³  ìµœì í™”í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        df = data_loader.load_from_database()
    if df.empty: st.error("ğŸ˜• ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return
    
    # ì‚¬ì´ë“œë°”
    user_profile, filter_conditions = render_enhanced_sidebar(df)
    
    # í•„í„° ì ìš©
    filtered_df = apply_filters(df, filter_conditions, user_profile)
    
    # í•„í„° ìš”ì•½
    active_filters = [f"**{k.replace('_', ' ').title()}:** `{v}`" for k, v in filter_conditions.items() if v and (isinstance(v, str) and v != 'ì „ì²´' or isinstance(v, bool) and v)]
    st.markdown(f'<div class="alert-success">ğŸ” <strong>ì ìš©ëœ í•„í„°:</strong> {(" | ".join(active_filters)) if active_filters else "ì „ì²´"} | <strong>ê²°ê³¼:</strong> {len(filtered_df):,}ê°œ ê³µê³ </div>', unsafe_allow_html=True)
    
    # íƒ­ êµ¬ì„±
    tabs = st.tabs(["â­ ë©”ì¸ ëŒ€ì‹œë³´ë“œ", "ğŸ¯ AI ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­", "ğŸ“ˆ ê°œì¸ ì„±ì¥ ê²½ë¡œ", "ğŸ“Š ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„", "ğŸ¢ ê¸°ì—… ì¸ì‚¬ì´íŠ¸", "ğŸ”® ì˜ˆì¸¡ ë¶„ì„", "ğŸ“‹ ìƒì„¸ ë°ì´í„°"])
    with tabs[0]: render_enhanced_main_summary(df)
    with tabs[1]: render_enhanced_smart_matching(filtered_df, user_profile, matching_engine, df)
    with tabs[2]: render_advanced_growth_path(df, user_profile, filter_conditions['user_category'], matching_engine)
    with tabs[3]: render_market_trend_dashboard(df)
    with tabs[4]: render_enhanced_company_insights(filtered_df)
    with tabs[5]: render_enhanced_prediction_analysis(df)
    with tabs[6]: render_detail_table(filtered_df)

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        st.error(f"ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        logger.error(f"Application error: {e}", exc_info=True)
