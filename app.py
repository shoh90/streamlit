# app.py - Rallit ìŠ¤ë§ˆíŠ¸ ì±„ìš© ëŒ€ì‹œë³´ë“œ (ìµœì¢… ì™„ì„±ë³¸, API ì¸ì¦ ë° ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”)

import streamlit as st
import pandas as pd
import sqlite3
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
from pathlib import Path
import logging
import random
import re
import requests
import xml.etree.ElementTree as ET
import folium
from streamlit_folium import st_folium

# ==============================================================================
# 1. í˜ì´ì§€ ë° í™˜ê²½ ì„¤ì •
# ==============================================================================
st.set_page_config(
    page_title="Rallit ìŠ¤ë§ˆíŠ¸ ì±„ìš© ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ==============================================================================
# 2. ì»¤ìŠ¤í…€ CSS
# ==============================================================================
st.markdown("""
<style>
    .problem-card { background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); padding: 1.5rem; border-radius: 15px; color: white; margin: 0.5rem 0; box-shadow: 0 8px 32px rgba(31, 38, 135, 0.37); min-height: 180px; }
    .skill-match { display: inline-block; background: #e8f5e8; padding: 0.3rem 0.6rem; border-radius: 15px; border: 1px solid #4caf50; margin: 0.2rem; font-size: 0.9em; color: #145a32; }
    .skill-gap { display: inline-block; background: #fff3e0; padding: 0.3rem 0.6rem; border-radius: 15px; border: 1px solid #ff9800; margin: 0.2rem; font-size: 0.9em; color: #9c5400;}
    .growth-indicator { background: linear-gradient(90deg, #a8edea 0%, #fed6e3 100%); padding: 0.8rem; border-radius: 10px; margin: 0.5rem 0; }
    h3 { padding-bottom: 10px; }
</style>
""", unsafe_allow_html=True)


# ==============================================================================
# 3. í•µì‹¬ í´ë˜ìŠ¤ ì •ì˜
# ==============================================================================
class SmartDataLoader:
    def __init__(self, db_path='rallit_jobs.db', data_dir='data'):
        self.db_path = db_path; self.data_dir = Path(data_dir)
        self.csv_files = {'MANAGEMENT': 'rallit_management_jobs.csv', 'MARKETING': 'rallit_marketing_jobs.csv', 'DESIGN': 'rallit_design_jobs.csv', 'DEVELOPER': 'rallit_developer_jobs.csv'}
    @st.cache_data
    def load_from_database(_self):
        try:
            if not Path(_self.db_path).exists(): _self._create_database_from_csv()
            conn = sqlite3.connect(_self.db_path); df = pd.read_sql_query("SELECT * FROM jobs", conn); conn.close()
            for col in ['join_reward', 'is_partner', 'is_bookmarked']:
                if col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
            return df
        except Exception: return _self._load_from_csv_fallback()
    def _load_from_csv_fallback(self):
        try:
            dfs = [pd.read_csv(self.data_dir / f).assign(job_category=cat) for cat, f in self.csv_files.items() if (self.data_dir / f).exists()]
            if not dfs: return self._load_sample_data()
            df = pd.concat(dfs, ignore_index=True)
            df.columns = [c.lower().replace(' ', '_').replace('.', '_') for c in df.columns]
            for col in ['join_reward', 'is_partner', 'is_bookmarked']:
                if col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
            return df
        except Exception: return self._load_sample_data()
    def _create_database_from_csv(self):
        df = self._load_from_csv_fallback()
        if not df.empty: conn = sqlite3.connect(self.db_path); df.to_sql('jobs', conn, if_exists='replace', index=False); conn.close()
    def _load_sample_data(self):
        st.warning("ğŸ“ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ìƒ˜í”Œ ë°ì´í„°ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."); categories = ['DEVELOPER', 'DESIGN', 'MARKETING', 'MANAGEMENT']; regions = ['PANGYO', 'GANGNAM', 'HONGDAE', 'JONGNO']; companies = ['í…Œí¬ì»´í¼ë‹ˆA', 'ìŠ¤íƒ€íŠ¸ì—…B', 'ëŒ€ê¸°ì—…C', 'AIìŠ¤íƒ€íŠ¸ì—…G']; skills = {'DEVELOPER': ['Python', 'JavaScript', 'React', 'Node.js', 'Java', 'Docker', 'AWS'], 'DESIGN': ['Figma', 'Sketch', 'Adobe XD', 'Zeplin'], 'MARKETING': ['Google Analytics', 'SEO', 'Content Marketing'], 'MANAGEMENT': ['Project Management', 'Agile', 'Scrum']}; data = []
        for i in range(150): cat = random.choice(categories); data.append({'id': i, 'job_category': cat, 'address_region': random.choice(regions), 'company_name': random.choice(companies), 'title': f'{cat.title()} ì±„ìš© - {random.choice(companies)}', 'status_name': random.choice(['ëª¨ì§‘ ì¤‘', 'ë§ˆê°']), 'status_code': 'HIRING', 'is_partner': random.choice([0, 1]), 'is_bookmarked': 0, 'join_reward': random.choice([0, 50000, 100000, 200000, 500000]), 'job_skill_keywords': ','.join(random.sample(skills[cat], k=random.randint(2, 4))), 'job_level': random.choice(['JUNIOR', 'SENIOR', 'LEAD', 'IRRELEVANT']), 'created_at': datetime.now()})
        return pd.DataFrame(data)

class SmartMatchingEngine:
    def calculate_skill_match(self, user_skills, job_requirements):
        if not user_skills or not job_requirements or not isinstance(job_requirements, str): return 0, [], []
        user_skills_set = {s.strip().lower() for s in user_skills if s.strip()}; job_skills_set = {s.strip().lower() for s in job_requirements.split(',') if s.strip()}
        if not job_skills_set: return 0, [], []
        intersection = user_skills_set.intersection(job_skills_set); match_score = (len(intersection) / len(job_skills_set)) * 100 if job_skills_set else 0
        return match_score, list(intersection), list(job_skills_set - user_skills_set)
    def analyze_growth_potential(self, user_profile):
        score, factors = 0, []; modern_skills = ['ai', 'ml', 'docker', 'kubernetes', 'react', 'vue', 'typescript']; user_skills_lower = [s.lower() for s in user_profile.get('skills', [])]
        if user_profile.get('recent_courses', 0) > 0: score += 20; factors.append(f"ìµœê·¼ í•™ìŠµ ({user_profile.get('recent_courses')}ê°œ)")
        if user_profile.get('project_count', 0) > 3: score += 25; factors.append(f"í”„ë¡œì íŠ¸ ê²½í—˜ ({user_profile.get('project_count')}ê°œ)")
        if len(user_profile.get('skills', [])) > 8: score += 20; factors.append(f"ê¸°ìˆ  ìŠ¤íƒ ë‹¤ì–‘ì„± ({len(user_profile.get('skills', []))}ê°œ)")
        if user_profile.get('github_contributions', 0) > 100: score += 15; factors.append(f"ì˜¤í”ˆì†ŒìŠ¤ ê¸°ì—¬ ({user_profile.get('github_contributions')}íšŒ)")
        if any(skill in modern_skills for skill in user_skills_lower): score += 20; factors.append("ìµœì‹  ê¸°ìˆ  íŠ¸ë Œë“œ ê´€ì‹¬")
        return min(score, 100), factors
    def predict_success_probability(self, skill_score, growth_score):
        return round((skill_score * 0.7 + growth_score * 0.3), 1)


# ==============================================================================
# 4. ë·°(View) í•¨ìˆ˜ ì •ì˜
# ==============================================================================
# (ì´í•˜ ë·° í•¨ìˆ˜ë“¤ì€ ì´ì „ê³¼ ë™ì¼í•˜ì—¬ ê°„ê²°í•¨ì„ ìœ„í•´ ìƒëµ. ì‹¤ì œ ì½”ë“œì—ëŠ” ëª¨ë‘ í¬í•¨ë˜ì–´ì•¼ í•¨)
def render_smart_matching(...): ...
def render_market_analysis(...): ...
def render_growth_path(...): ...
def render_company_insight(...): ...
def render_prediction_analysis(...): ...
def render_detail_table(...): ...

# <<< ìˆ˜ì •ëœ ë¶€ë¶„ ì‹œì‘ >>>
@st.cache_data(ttl=3600) # 1ì‹œê°„ ë™ì•ˆ API í˜¸ì¶œ ê²°ê³¼ ìºì‹œ
def fetch_labor_trend_data():
    """ê³ ìš©ë…¸ë™ë¶€ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì‹¤ì‹œê°„ ì±„ìš© ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    url = "https://eis.work24.go.kr/opi/joApi.do"
    
    # Streamlit Secretsì—ì„œ ì¸ì¦í‚¤ë¥¼ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜´
    auth_key = st.secrets.get("EIS_AUTH_KEY")
    
    # ì¸ì¦í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ì„ ê²½ìš° API í˜¸ì¶œ ì‹œë„í•˜ì§€ ì•ŠìŒ
    if not auth_key:
        logger.warning("EIS_AUTH_KEY is not set in Streamlit Secrets.")
        return None, "NO_KEY"
        
    params = {
        'authKey': auth_key,
        'apiSecd': 'OPIA',
        'rernSecd': 'XML',
        'display': 100, # ìµœëŒ€ 100ê°œ ë°ì´í„° ìš”ì²­
        'closStdrYm': datetime.now().strftime('%Y%m') # í˜„ì¬ ë…„ì›” ê¸°ì¤€
    }
    
    try:
        response = requests.get(url, params=params, timeout=10)
        
        # HTML ì‘ë‹µ ë˜ëŠ” ì—ëŸ¬ ì‘ë‹µ ì²˜ë¦¬
        if response.status_code != 200 or '<!DOCTYPE html>' in response.text:
            logger.error(f"API Error: Status {response.status_code}. Response might be HTML.")
            return None, "API_ERROR"
            
        # XML íŒŒì‹±
        root = ET.fromstring(response.text)
        data_list = []
        for item in root.findall('.//item'):
            data = {child.tag: child.text for child in item}
            data_list.append(data)
        
        return data_list, "SUCCESS"
        
    except (requests.exceptions.RequestException, ET.ParseError) as e:
        logger.error(f"API Request or XML Parsing failed: {e}")
        return None, "REQUEST_FAIL"

def render_labor_trend_analysis():
    st.header("ğŸ’¡ ì‹¤ì‹œê°„ ë…¸ë™ì‹œì¥ íŠ¸ë Œë“œ (ê³ ìš©ë…¸ë™ë¶€ API)")
    
    with st.spinner("ì‹¤ì‹œê°„ ê³ ìš© ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
        trend_data, status = fetch_labor_trend_data()
    
    if status == "SUCCESS" and trend_data:
        trends_df = pd.DataFrame(trend_data)
        
        st.subheader("ğŸ—ºï¸ ì§€ë„ ê¸°ë°˜ ì‹¤ì‹œê°„ ì±„ìš© ìˆ˜ìš”")
        location_dict = {"ì„œìš¸": [37.5665, 126.9780], "ë¶€ì‚°": [35.1796, 129.0756], "ëŒ€êµ¬": [35.8714, 128.6014], "ì¸ì²œ": [37.4563, 126.7052], "ê´‘ì£¼": [35.1595, 126.8526], "ëŒ€ì „": [36.3504, 127.3845], "ìš¸ì‚°": [35.5384, 129.3114], "ì„¸ì¢…": [36.4801, 127.2891], "ê²½ê¸°": [37.4138, 127.5183], "ê°•ì›": [37.8228, 128.1555], "ì¶©ë¶": [36.6358, 127.4917], "ì¶©ë‚¨": [36.5184, 126.8000], "ì „ë¶": [35.7167, 127.1442], "ì „ë‚¨": [34.8161, 126.4630], "ê²½ë¶": [36.4919, 128.8889], "ê²½ë‚¨": [35.4606, 128.2132], "ì œì£¼": [33.4996, 126.5312]}
        
        trends_df['region_simple'] = trends_df['region'].str.split().str[0].str.replace("íŠ¹ë³„ì‹œ", "").str.replace("ê´‘ì—­ì‹œ", "").str.replace("íŠ¹ë³„ìì¹˜ì‹œ", "").str.replace("íŠ¹ë³„ìì¹˜ë„", "")
        region_counts = trends_df['region_simple'].value_counts()
        
        m = folium.Map(location=[36.5, 127.8], zoom_start=7, tiles="cartodbpositron")
        for region, count in region_counts.items():
            if region in location_dict:
                folium.CircleMarker(location=location_dict[region], radius=max(5, count), popup=f"{region}: {count}ê±´", color='#3186cc', fill=True, fill_color='#3186cc', fill_opacity=0.6).add_to(m)
        st_folium(m, width=1000, height=400, key="folium_map")

    elif status == "NO_KEY":
        st.error("ğŸš¨ API ì¸ì¦í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Cloudì˜ Secretsì— `EIS_AUTH_KEY`ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    else:
        st.warning(f"âš ï¸ ê³ ìš©ë…¸ë™ë¶€ APIì—ì„œ ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (ì˜¤ë¥˜ ì½”ë“œ: {status}). ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
# <<< ìˆ˜ì •ëœ ë¶€ë¶„ ë >>>


# ==============================================================================
# 5. ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
# ==============================================================================
def main():
    st.title("Rallit ìŠ¤ë§ˆíŠ¸ ì±„ìš© ëŒ€ì‹œë³´ë“œ")
    with st.expander("âœ¨ ëŒ€ì‹œë³´ë“œ ê¸°íš ì˜ë„ ìì„¸íˆ ë³´ê¸°"):
        st.markdown("## ğŸ¯ í•´ê²°í•˜ê³ ì í•˜ëŠ” ë¬¸ì œë“¤")
        c1,c2,c3 = st.columns(3); c1.markdown('<div class="problem-card"><h3>ğŸ‘¤ êµ¬ì§ì ë¬¸ì œ</h3><ul><li>ì í•©í•œ ê³µê³  ì°¾ê¸° ì–´ë ¤ì›€</li><li>JD-ìŠ¤í™ ë¯¸ìŠ¤ë§¤ì¹­</li><li>ì„±ì¥ê³¼ì • í‰ê°€ ë¶€ì¡±</li></ul></div>', unsafe_allow_html=True); c2.markdown('<div class="problem-card"><h3>ğŸ¢ ê¸°ì—… ë¬¸ì œ</h3><ul><li>ì‹¤ë¬´ì—­ëŸ‰ íŒë‹¨ ì–´ë ¤ì›€</li><li>ì •ëŸ‰ì  ê¸°ì¤€ ë¶€ì¡±</li><li>ì„±ê³¼ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥</li></ul></div>', unsafe_allow_html=True); c3.markdown('<div class="problem-card"><h3>ğŸ”§ í”Œë«í¼ ë¬¸ì œ</h3><ul><li>ì„±ì¥ì—¬ì • ë¯¸ë°˜ì˜</li><li>ë‹¨ìˆœ í‚¤ì›Œë“œ ë§¤ì¹­</li><li>ìµœì‹  íŠ¸ë Œë“œ ë¶€ì¡±</li></ul></div>', unsafe_allow_html=True)
    st.markdown("---")
    
    data_loader = SmartDataLoader(); matching_engine = SmartMatchingEngine(); df = data_loader.load_from_database()
    if df.empty: st.error("ğŸ˜• ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return

    with st.sidebar:
        st.header("ğŸ¯ ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­ í”„ë¡œí•„"); user_skills_input = st.text_area("ë³´ìœ  ê¸°ìˆ  ìŠ¤íƒ (ì‰¼í‘œë¡œ êµ¬ë¶„)", placeholder="ì˜ˆ: Python, React, AWS")
        with st.expander("ğŸ“ˆ ì„±ì¥ í”„ë¡œí•„ (ì„ íƒ)"): recent_courses = st.number_input("ìµœê·¼ 1ë…„ ìˆ˜ê°• ê°•ì˜ ìˆ˜", 0, 50, 0); project_count = st.number_input("ê°œì¸/íŒ€ í”„ë¡œì íŠ¸ ìˆ˜", 0, 20, 0); github_contributions = st.number_input("GitHub ì—°ê°„ ê¸°ì—¬ë„", 0, 1000, 0)
        user_profile = {'skills': [s.strip() for s in user_skills_input.split(',') if s.strip()], 'recent_courses': recent_courses, 'project_count': project_count, 'github_contributions': github_contributions}
        
        st.markdown("---"); st.header("ğŸ” ê³ ê¸‰ í•„í„°"); user_category = st.selectbox("ê´€ì‹¬ ì§ë¬´", ['ì „ì²´'] + sorted(list(df['job_category'].dropna().unique()))); selected_region = st.selectbox("ğŸ“ ê·¼ë¬´ ì§€ì—­", ['ì „ì²´'] + sorted(list(df['address_region'].dropna().unique())))
        reward_filter = st.checkbox("ğŸ’° ì§€ì›ê¸ˆ ìˆëŠ” ê³µê³ ë§Œ ë³´ê¸°"); partner_filter = st.checkbox("ğŸ¤ íŒŒíŠ¸ë„ˆ ê¸°ì—…ë§Œ ë³´ê¸°")
        min_r, max_r = int(df['join_reward'].min()), int(df['join_reward'].max()); join_reward_range = st.slider("ğŸ’µ ì§€ì›ê¸ˆ ë²”ìœ„ (ì›)", min_r, max_r, (min_r, max_r))
        selected_levels = st.multiselect("ğŸ“ˆ ì§ë¬´ ë ˆë²¨", df['job_level'].dropna().unique(), default=list(df['job_level'].dropna().unique())); keyword_input = st.text_input("ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰ (ê³µê³ ëª…/íšŒì‚¬ëª…)", "")
        if st.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"): st.cache_data.clear(); st.rerun()

    filtered_df = df.copy()
    if user_category != 'ì „ì²´': filtered_df = filtered_df[filtered_df['job_category'] == user_category]
    if selected_region != 'ì „ì²´': filtered_df = filtered_df[filtered_df['address_region'] == selected_region]
    if reward_filter: filtered_df = filtered_df[filtered_df['join_reward'] > 0]
    if partner_filter: filtered_df = filtered_df[filtered_df['is_partner'] == 1]
    if selected_levels: filtered_df = filtered_df[filtered_df['job_level'].isin(selected_levels)]
    filtered_df = filtered_df[filtered_df['join_reward'].between(join_reward_range[0], join_reward_range[1])]
    if keyword_input:
        keyword = keyword_input.lower()
        mask = (filtered_df['title'].str.lower().str.contains(keyword, na=False)) | (filtered_df['company_name'].str.lower().str.contains(keyword, na=False))
        filtered_df = filtered_df[mask]
    if user_profile['skills'] and 'job_skill_keywords' in filtered_df.columns:
        user_skills_pattern = '|'.join([re.escape(skill.strip()) for skill in user_profile['skills']])
        filtered_df = filtered_df[filtered_df['job_skill_keywords'].str.contains(user_skills_pattern, case=False, na=False)]

    summary_list = [f"**ë³´ìœ  ìŠ¤í‚¬:** `{', '.join(user_profile['skills'])}`" if user_profile['skills'] else '', f"**ì§ë¬´:** `{user_category}`" if user_category != 'ì „ì²´' else '', f"**ì§€ì—­:** `{selected_region}`" if selected_region != 'ì „ì²´' else '', f"**í‚¤ì›Œë“œ:** `{keyword_input}`" if keyword_input else '']
    active_filters = " | ".join(filter(None, summary_list))
    st.success(f"ğŸ” **í•„í„° ìš”ì•½:** {active_filters if active_filters else 'ì „ì²´ ì¡°ê±´'} | **ê²°ê³¼:** `{len(filtered_df)}`ê°œì˜ ê³µê³ ")

    tabs = st.tabs(["ğŸ¯ ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­", "ğŸ“Š ì‹œì¥ ë¶„ì„", "ğŸ’¡ ë…¸ë™ì‹œì¥ íŠ¸ë Œë“œ", "ğŸ“ˆ ì„±ì¥ ê²½ë¡œ", "ğŸ¢ ê¸°ì—… ì¸ì‚¬ì´íŠ¸", "ğŸ”® ì˜ˆì¸¡ ë¶„ì„", "ğŸ“‹ ìƒì„¸ ë°ì´í„°"])
    with tabs[0]: render_smart_matching(filtered_df, user_profile, matching_engine, df)
    with tabs[1]: render_market_analysis(filtered_df)
    with tabs[2]: render_labor_trend_analysis()
    with tabs[3]: render_growth_path(df, user_profile, user_category, matching_engine)
    with tabs[4]: render_company_insight(filtered_df)
    with tabs[5]: render_prediction_analysis()
    with tabs[6]: render_detail_table(filtered_df)

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        st.error(f"ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"); logger.error(f"Application error: {e}", exc_info=True)
