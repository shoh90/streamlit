# app.py - Rallit ìŠ¤ë§ˆíŠ¸ ì±„ìš© ëŒ€ì‹œë³´ë“œ (ìµœì¢… ê³ ë„í™” ë²„ì „, êµ¬ë¬¸ ì˜¤ë¥˜ ìˆ˜ì •)

import streamlit as st
import pandas as pd
import sqlite3
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
from pathlib import Path
import logging
import random
import re
import numpy as np

# ==============================================================================
# 1. í˜ì´ì§€ ë° í™˜ê²½ ì„¤ì •
# ==============================================================================
st.set_page_config(
    page_title="ê°“ìƒë¼ì´í”„/ì»¤ë¦¬ì–´í•˜ì´ì–´ - AI ê¸°ë°˜ ì„±ì¥í˜• ì±„ìš© í”Œë«í¼",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ==============================================================================
# 2. ì»¤ìŠ¤í…€ CSS
# ==============================================================================
st.markdown("""
<style>
    .stTabs [data-baseweb="tab-list"] { gap: 8px; }
    .stTabs [data-baseweb="tab"] { height: 50px; background-color: #f0f2f6; border-radius: 8px; border: none; color: #555; font-weight: 600; }
    .stTabs [data-baseweb="tab"]:hover { background-color: #e2e8f0; color: #333; }
    .stTabs [aria-selected="true"] { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; }
    .main-header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 2rem; border-radius: 20px; margin-bottom: 2rem; color: white; text-align: center; box-shadow: 0 10px 30px rgba(0,0,0,0.2); }
    .main-header h1 { font-size: 2.5rem; margin-bottom: 0.5rem; font-weight: 700; }
    .main-header p { font-size: 1.2rem; opacity: 0.9; margin: 0; }
    .kpi-card { background: #FFFFFF; padding: 1.5rem; border-radius: 15px; border: 1px solid #e2e8f0; box-shadow: 0 4px 12px rgba(0,0,0,0.08); text-align: center; height: 100%; transition: transform 0.2s, box-shadow 0.2s; }
    .kpi-card:hover { transform: translateY(-5px); box-shadow: 0 8px 16px rgba(0,0,0,0.12); }
    .kpi-card h3 { font-size: 1rem; color: #4a5568; margin-bottom: 0.5rem; font-weight: 600; }
    .kpi-card p { font-size: 2.2rem; font-weight: 700; color: #2d3748; margin: 0; }
    .kpi-card small { font-size: 0.85rem; color: #718096; }
    .skill-match { display: inline-block; background: #e8f5e8; color: #38a169; padding: 0.4rem 0.8rem; border-radius: 20px; margin: 0.2rem; font-size: 0.85em; font-weight: 600; border: 1px solid #a7f3d0; }
    .skill-gap { display: inline-block; background: #fffaf0; color: #dd6b20; padding: 0.4rem 0.8rem; border-radius: 20px; margin: 0.2rem; font-size: 0.85em; font-weight: 600; border: 1px solid #fbd38d; }
    .growth-indicator { background: #f0f9ff; padding: 1rem; border-radius: 15px; margin: 0.5rem 0; border-left: 4px solid #667eea; box-shadow: 0 2px 8px rgba(0,0,0,0.05); }
    .alert-success { background: #f0fff4; color: #166534; padding: 1rem; border-radius: 10px; margin: 1rem 0; border: 1px solid #a7f3d0;}
</style>
""", unsafe_allow_html=True)


# ==============================================================================
# 3. í•µì‹¬ í´ë˜ìŠ¤ ì •ì˜
# ==============================================================================
class EnhancedSmartDataLoader:
    def __init__(self, db_path='rallit_jobs.db', data_dir='data'):
        self.db_path = db_path; self.data_dir = Path(data_dir)
        self.csv_files = {'MANAGEMENT': 'rallit_management_jobs.csv', 'MARKETING': 'rallit_marketing_jobs.csv', 'DESIGN': 'rallit_design_jobs.csv', 'DEVELOPER': 'rallit_developer_jobs.csv'}
    @st.cache_data(ttl=3600)
    def load_from_database(_self):
        try:
            if not Path(_self.db_path).exists(): _self._create_database_from_csv()
            conn = sqlite3.connect(_self.db_path); df = pd.read_sql_query("SELECT * FROM jobs", conn); conn.close()
            return _self._optimize_dataframes(df)
        except Exception as e: return _self._load_from_csv_fallback()
    def _optimize_dataframes(self, df):
        for col in ['join_reward', 'is_partner', 'is_bookmarked', 'age', 'experience_years', 'remote_possible']:
            if col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        if 'created_at' in df.columns: df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')
        for col in ['job_category', 'address_region', 'status_code', 'job_level', 'gender', 'education_level', 'company_size']:
            if col in df.columns: df[col] = df[col].astype('category')
        return df
    def _load_from_csv_fallback(self):
        try:
            dfs = [pd.read_csv(self.data_dir / f).assign(job_category=cat) for cat, f in self.csv_files.items() if (self.data_dir / f).exists()]
            if not dfs: return self._generate_enhanced_sample_data()
            df = pd.concat(dfs, ignore_index=True)
            df.columns = [c.lower().replace(' ', '_').replace('.', '_') for c in df.columns]
            return self._enrich_data(df)
        except Exception as e: return self._generate_enhanced_sample_data()
    def _create_database_from_csv(self):
        df = self._load_from_csv_fallback()
        if not df.empty: conn = sqlite3.connect(self.db_path); df.to_sql('jobs', conn, if_exists='replace', index=False); conn.close()
    def _enrich_data(self, df):
        if 'age' not in df.columns: df['age'] = np.random.normal(32, 8, len(df)).clip(22, 65).astype(int)
        if 'gender' not in df.columns: df['gender'] = np.random.choice(['ë‚¨ì„±', 'ì—¬ì„±'], len(df), p=[0.52, 0.48])
        if 'experience_years' not in df.columns: df['experience_years'] = np.random.gamma(2, 2, len(df)).clip(0, 20).astype(int)
        if 'education_level' not in df.columns: df['education_level'] = np.random.choice(['ê³ ë“±í•™êµ', 'ì „ë¬¸ëŒ€', 'ëŒ€í•™êµ', 'ëŒ€í•™ì›'], len(df), p=[0.1, 0.2, 0.6, 0.1])
        if 'job_skill_keywords' not in df.columns or df['job_skill_keywords'].isna().all(): df['job_skill_keywords'] = df['job_category'].apply(self._generate_skills_by_category)
        if 'created_at' not in df.columns: df['created_at'] = [datetime.now() - timedelta(days=random.randint(0, 365)) for _ in range(len(df))]
        if 'company_size' not in df.columns: df['company_size'] = np.random.choice(['ìŠ¤íƒ€íŠ¸ì—…(1-50ëª…)', 'ì¤‘ì†Œê¸°ì—…(51-300ëª…)', 'ì¤‘ê²¬ê¸°ì—…(301-1000ëª…)', 'ëŒ€ê¸°ì—…(1000ëª…+)'], len(df), p=[0.4, 0.35, 0.15, 0.1])
        if 'remote_possible' not in df.columns: df['remote_possible'] = np.random.choice([0, 1], len(df), p=[0.6, 0.4])
        return df
    def _generate_skills_by_category(self, category):
        skill_pools = {'DEVELOPER': ['Python', 'Java', 'JavaScript', 'React', 'Vue.js', 'Node.js', 'Spring', 'Docker', 'Kubernetes', 'AWS', 'GCP', 'MySQL', 'PostgreSQL', 'MongoDB', 'Redis', 'Git', 'Jenkins', 'TypeScript', 'Go', 'Kotlin'], 'DESIGN': ['Figma', 'Sketch', 'Adobe XD', 'Photoshop', 'Illustrator', 'Principle', 'Zeplin', 'InVision', 'Framer', 'After Effects', 'UI/UX', 'Prototyping', 'Wireframing', 'User Research'], 'MARKETING': ['Google Analytics', 'Facebook Ads', 'Google Ads', 'SEO', 'SEM', 'Content Marketing', 'Email Marketing', 'Social Media', 'Adobe Creative Suite', 'Hootsuite', 'Mailchimp', 'HubSpot', 'Salesforce'], 'MANAGEMENT': ['Agile', 'Scrum', 'Kanban', 'Jira', 'Confluence', 'Slack', 'Notion', 'Excel', 'PowerPoint', 'Project Management', 'Leadership', 'Team Building', 'Strategic Planning']}
        skills = skill_pools.get(category, ['Communication', 'Teamwork', 'Problem Solving']); return ', '.join(random.sample(skills, min(random.randint(3, 8), len(skills))))
    def _generate_enhanced_sample_data(self):
        st.warning("ğŸ“ ì‹¤ì œ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê³ ë„í™”ëœ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."); sample_size = 1000; categories = ['DEVELOPER', 'DESIGN', 'MARKETING', 'MANAGEMENT']; regions = ['PANGYO', 'GANGNAM', 'HONGDAE', 'JONGNO', 'SEONGSU', 'YEOUIDO', 'BUNDANG', 'ILSAN']; companies = ['í…Œí¬ìŠ¤íƒ€íŠ¸ì—…A', 'AIì»´í¼ë‹ˆB', 'ë¹…ë°ì´í„°C', 'í•€í…Œí¬D', 'ì´ì»¤ë¨¸ìŠ¤E', 'ê²Œì„íšŒì‚¬F', 'ì—”í„°í…Œì¸ë¨¼íŠ¸G', 'ë¡œì§€ìŠ¤í‹±ìŠ¤H', 'í—¬ìŠ¤ì¼€ì–´I', 'ì—ë“€í…Œí¬J', 'ì‚¼ì„±ì „ì', 'LGì „ì', 'ë„¤ì´ë²„', 'ì¹´ì¹´ì˜¤', 'ì¿ íŒ¡', 'ë°°ë‹¬ì˜ë¯¼ì¡±', 'KBêµ­ë¯¼ì€í–‰', 'SKí…”ë ˆì½¤']; job_levels = ['ENTRY', 'JUNIOR', 'SENIOR', 'LEAD', 'MANAGER', 'DIRECTOR']
        data = [{'id': i + 1, 'job_category': category, 'address_region': random.choice(regions), 'company_name': random.choice(companies), 'title': f'{category} ì „ë¬¸ê°€', 'is_partner': random.choice([0, 1]), 'join_reward': random.choice([0, 50000, 100000, 200000, 300000, 500000, 1000000]), 'job_skill_keywords': self._generate_skills_by_category(category), 'job_level': random.choice(job_levels), 'status_code': random.choice(['RECRUITING', 'CLOSED', 'PENDING'])} for i, category in enumerate(np.random.choice(categories, sample_size))]
        return self._enrich_data(pd.DataFrame(data))

class AdvancedMatchingEngine:
    def __init__(self): self.skill_weights = {'python': 1.2, 'java': 1.1, 'javascript': 1.1, 'react': 1.15, 'aws': 1.2, 'docker': 1.1, 'kubernetes': 1.1, 'ai': 1.3, 'ml': 1.3, 'figma': 1.1, 'google analytics': 1.1}
    def calculate_advanced_skill_match(self, user_skills, job_requirements, job_category=None):
        if not user_skills or not job_requirements or not isinstance(job_requirements, str): return 0, [], [], {}
        user_skills_clean = [s.strip().lower() for s in user_skills if s.strip()]; job_skills_clean = [s.strip().lower() for s in job_requirements.split(',') if s.strip()]
        if not job_skills_clean: return 0, [], [], {}
        user_set = set(user_skills_clean); job_set = set(job_skills_clean); intersection = user_set.intersection(job_set); missing = job_set - user_set
        weighted_score = sum(self.skill_weights.get(s, 1.0) for s in intersection); total_weight = sum(self.skill_weights.get(s, 1.0) for s in job_skills_clean)
        match_score = (weighted_score / total_weight * 100) if total_weight > 0 else 0
        category_bonus = self._calculate_category_bonus(user_skills_clean, job_category); final_score = min(match_score + category_bonus, 100)
        analysis = {'basic_score': len(intersection) / len(job_set) * 100 if job_set else 0, 'weighted_score': match_score, 'category_bonus': category_bonus}
        return final_score, list(intersection), list(missing), analysis
    def _calculate_category_bonus(self, user_skills, job_category):
        if not job_category: return 0
        category_skills = {'DEVELOPER': ['python', 'java', 'react'], 'DESIGN': ['figma', 'ui/ux'], 'MARKETING': ['seo', 'google analytics'], 'MANAGEMENT': ['agile', 'jira']}
        relevant_skills = category_skills.get(job_category, []); matching_relevant = sum(1 for s in user_skills if s in relevant_skills)
        return min(matching_relevant * 2, 10)
    def analyze_advanced_growth_potential(self, user_profile):
        score, factors, analysis = 0, [], {};
        learning_score = min(user_profile.get('recent_courses', 0) * 5, 25); score += learning_score; analysis['learning_score'] = learning_score; factors.append(f"í•™ìŠµ í™œë™: {learning_score}ì ") if learning_score > 0 else None
        project_score = min(user_profile.get('project_count', 0) * 5, 30); score += project_score; analysis['project_score'] = project_score; factors.append(f"í”„ë¡œì íŠ¸ ê²½í—˜: {project_score}ì ") if project_score > 0 else None
        diversity_score = min(len(user_profile.get('skills', [])) * 2, 20); score += diversity_score; analysis['diversity_score'] = diversity_score; factors.append(f"ê¸°ìˆ  ë‹¤ì–‘ì„±: {diversity_score}ì ") if diversity_score > 0 else None
        oss_score = min(user_profile.get('github_contributions', 0) / 10, 15); score += oss_score; analysis['oss_score'] = oss_score; factors.append(f"ì˜¤í”ˆì†ŒìŠ¤ ê¸°ì—¬: {oss_score:.1f}ì ") if oss_score > 0 else None
        modern_skills = ['ai', 'ml', 'kubernetes', 'react', 'typescript']; trend_score = min(sum(1 for s in user_profile.get('skills', []) if s.lower() in modern_skills) * 2, 10); score += trend_score; analysis['trend_score'] = trend_score; factors.append(f"ìµœì‹  ê¸°ìˆ  ê´€ì‹¬: {trend_score}ì ") if trend_score > 0 else None
        analysis['total_score'] = min(score, 100); return analysis['total_score'], factors, analysis
    def predict_advanced_success_probability(self, skill_score, growth_score):
        prob = round((skill_score * 0.6 + growth_score * 0.4), 1); return {'probability': min(prob, 95.0), 'confidence': max(60, (skill_score + growth_score) / 2)}

class TrendAnalyzer:
    def __init__(self, df): self.df = df
    def analyze_skill_trends(self):
        if 'job_skill_keywords' not in self.df.columns: return {}
        recent_cutoff = datetime.now() - timedelta(days=180); recent_df = self.df[self.df['created_at'] >= recent_cutoff] if 'created_at' in self.df.columns else self.df
        all_skills = self._extract_skills(self.df); recent_skills = self._extract_skills(recent_df)
        growth_rates = {}
        for skill in set(all_skills.keys()) | set(recent_skills.keys()):
            all_count = all_skills.get(skill, 0); recent_count = recent_skills.get(skill, 0)
            if all_count > 0: annualized_recent = recent_count * 2; growth_rates[skill] = ((annualized_recent - all_count) / all_count) * 100
        return {'trending_up': dict(sorted(growth_rates.items(), key=lambda x: x[1], reverse=True)[:5]), 'trending_down': dict(sorted(growth_rates.items(), key=lambda x: x[1])[:5])}
    def _extract_skills(self, df):
        skills_series = df['job_skill_keywords'].dropna().str.split(',').explode().str.strip().str.lower(); return skills_series[skills_series != ''].value_counts().to_dict()


# ==============================================================================
# 4. ë·°(View) í•¨ìˆ˜ ì •ì˜
# ==============================================================================
def render_enhanced_main_summary(df):
    st.markdown('<div class="main-header fade-in"><h1>ğŸš€ ê°“ìƒë¼ì´í”„/ì»¤ë¦¬ì–´í•˜ì´ì–´</h1><p>AI ê¸°ë°˜ ì„±ì¥í˜• ì±„ìš© í”Œë«í¼ - "ì„±ì¥ì„ ì¦ëª…í•˜ê³ , ì‹ ë¢°ë¥¼ ì—°ê²°í•˜ë‹¤"</p></div>', unsafe_allow_html=True)
    cols = st.columns(4)
    kpis = {'ì´ ê³µê³ ': len(df), 'ì°¸ì—¬ ê¸°ì—…': df['company_name'].nunique(), 'í‰ê·  ì§€ì›ê¸ˆ': df['join_reward'].mean() if 'join_reward' in df.columns else 0, 'ì›ê²©ê·¼ë¬´': df['remote_possible'].sum() if 'remote_possible' in df.columns else 0}
    icons = ['ğŸ“Š', 'ğŸ¢', 'ğŸ’°', 'ğŸ ']
    for col, icon, (k, v) in zip(cols, icons, kpis.items()):
        with col: st.markdown(f'<div class="kpi-card"><h3>{icon} {k}</h3><p>{v:,.0f}{"ê°œ" if k != "í‰ê·  ì§€ì›ê¸ˆ" else "ì›"}</p></div>', unsafe_allow_html=True)
    st.markdown("---")
    col1, col2 = st.columns([0.6, 0.4])
    with col1:
        st.subheader("ğŸŒ ì§€ì—­ë³„ ì±„ìš© ê³µê³  ë¶„í¬"); location_dict = {"ì„œìš¸": [37.5665, 126.9780], "ë¶€ì‚°": [35.1796, 129.0756], "ëŒ€êµ¬": [35.8714, 128.6014], "ì¸ì²œ": [37.4563, 126.7052], "ê´‘ì£¼": [35.1595, 126.8526], "ëŒ€ì „": [36.3504, 127.3845], "ìš¸ì‚°": [35.5384, 129.3114], "ì„¸ì¢…": [36.4801, 127.2891], "ê²½ê¸°": [37.4138, 127.5183], "ê°•ì›": [37.8228, 128.1555], "ì¶©ë¶": [36.6358, 127.4917], "ì¶©ë‚¨": [36.5184, 126.8000], "ì „ë¶": [35.7167, 127.1442], "ì „ë‚¨": [34.8161, 126.4630], "ê²½ë¶": [36.4919, 128.8889], "ê²½ë‚¨": [35.4606, 128.2132], "ì œì£¼": [33.4996, 126.5312], "PANGYO": [37.394776, 127.111195], "GANGNAM": [37.4979, 127.0276], "HONGDAE":[37.5575, 126.9245], "JONGNO":[37.5728, 126.9793], "SEONGSU":[37.5445, 127.0560], "YEOUIDO":[37.5252, 126.9255], "BUNDANG":[37.3828, 127.1189], "ILSAN":[37.6584, 126.7725]}
        region_counts = df['address_region'].value_counts()
        m = folium.Map(location=[36.5, 127.8], zoom_start=6.5, tiles="cartodbpositron")
        for region, count in region_counts.items():
            if region.upper() in location_dict: folium.CircleMarker(location=location_dict[region.upper()], radius=max(5, count / 10), popup=f"{region}: {count}ê±´", color='#3186cc', fill=True, fill_color='#3186cc', fill_opacity=0.7).add_to(m)
        st_folium(m, height=400, use_container_width=True)
    with col2:
        st.subheader("ğŸ¯ ì§ë¬´ ì¹´í…Œê³ ë¦¬ ë¶„í¬"); category_counts = df['job_category'].value_counts()
        fig = px.pie(category_counts, values=category_counts.values, names=category_counts.index, title="", hole=0.5); fig.update_layout(showlegend=False, margin=dict(l=0, r=0, t=0, b=0), height=400); fig.update_traces(textposition='inside', textinfo='percent+label'); st.plotly_chart(fig, use_container_width=True, config={'displayModeBar': False})

def render_advanced_growth_path(df, user_profile, target_category, matching_engine):
    st.header("ğŸ“ˆ AI ê¸°ë°˜ ê°œì¸ ì„±ì¥ ê²½ë¡œ"); st.caption("ìŠ¤í‚¬ ê¸°ë°˜ ì±„ìš©(Skills-Based Hiring) íŠ¸ë Œë“œ ë°˜ì˜")
    if not user_profile['skills']: st.markdown('<div class="alert-info"><h4>ğŸš€ ì„±ì¥ ê²½ë¡œë¥¼ íƒìƒ‰í•´ë³´ì„¸ìš”!</h4><p>ì‚¬ì´ë“œë°”ì— í”„ë¡œí•„ì„ ì…ë ¥í•˜ë©´ AIê°€ ë§ì¶¤í˜• ì„±ì¥ ë¡œë“œë§µì„ ì œì‹œí•©ë‹ˆë‹¤.</p></div>', unsafe_allow_html=True); return
    growth_generator = GrowthPathGenerator(df); growth_score, factors, detailed_analysis = matching_engine.analyze_advanced_growth_potential(user_profile)
    if target_category == 'ì „ì²´': target_category = 'DEVELOPER' # ê¸°ë³¸ê°’
    personalized_path = growth_generator.generate_personalized_path(user_profile, target_category)
    
    st.subheader("ğŸš€ ë‹¹ì‹ ì˜ ì„±ì¥ ì ì¬ë ¥"); c1, c2 = st.columns([1, 2]);
    with c1: fig = go.Figure(go.Indicator(mode="gauge+number", value=growth_score, title={'text': "ì„±ì¥ ì ì¬ë ¥"}, domain={'x': [0, 1], 'y': [0, 1]}, gauge={'axis': {'range': [None, 100]}})); st.plotly_chart(fig, use_container_width=True, key="growth_gauge_path")
    with c2:
        st.markdown("**ğŸŒ± ì„±ì¥ ìš”ì¸ ë¶„ì„:**");
        if factors: [st.markdown(f'<div class="growth-indicator">{f}</div>', unsafe_allow_html=True) for f in factors]
        else: st.write("ì„±ì¥ í”„ë¡œí•„ì„ ì…ë ¥í•˜ë©´ ë” ì •í™•í•œ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    st.markdown("---"); st.subheader("ğŸ—ºï¸ ì»¤ë¦¬ì–´ ë¡œë“œë§µ")
    roadmap = personalized_path.get('career_roadmap', [])
    for item in roadmap: st.progress(item['completion_rate'] / 100, text=f"{item['level']} ({item['completed_skills']}/{item['total_skills']})")
    
    st.subheader("ğŸ“š ë‹¤ìŒ ìŠ¤í…: ì¶”ì²œ í•™ìŠµ ìŠ¤í‚¬"); next_skills = personalized_path.get('next_skills', [])
    if next_skills: cols = st.columns(len(next_skills));
    for i, skill in enumerate(next_skills):
        with cols[i]: st.info(f"**{i+1}. {skill}**")

def render_market_trend_dashboard(df):
    st.header("ğŸ“Š ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„")
    trend_analyzer = TrendAnalyzer(df)
    skill_trends = trend_analyzer.analyze_skill_trends()
    if skill_trends:
        st.subheader("ğŸ“ˆ ê¸°ìˆ  íŠ¸ë Œë“œ ë¶„ì„")
        c1, c2 = st.columns(2)
        with c1:
            st.markdown("**ğŸš€ ê¸‰ìƒìŠ¹ ê¸°ìˆ **")
            for skill, growth in skill_trends.get('trending_up', {}).items():
                if growth > 0: st.markdown(f'<div class="growth-indicator">{skill.title()} <span style="color: #4CAF50; font-weight: bold;">â–² {growth:.1f}%</span></div>', unsafe_allow_html=True)
        with c2:
            st.markdown("**ğŸ“‰ í•˜ë½ ê¸°ìˆ **")
            for skill, decline in skill_trends.get('trending_down', {}).items():
                if decline < 0: st.markdown(f'<div class="growth-indicator" style="background: #ffebee;">{skill.title()} <span style="color: #f44336; font-weight: bold;">â–¼ {abs(decline):.1f}%</span></div>', unsafe_allow_html=True)
    st.markdown("---"); create_advanced_skill_visualization(df)

# (ë‹¤ë¥¸ ë·° í•¨ìˆ˜ë“¤ì€ ì´ì „ ë‹µë³€ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€)
def render_smart_matching(...): ...
def render_company_insight(...): ...
def render_prediction_analysis(...): ...
def render_detail_table(...): ...

# ==============================================================================
# 6. ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
# ==============================================================================
def main():
    # ë°ì´í„° ë¡œë”©
    data_loader = EnhancedSmartDataLoader(); matching_engine = AdvancedMatchingEngine()
    with st.spinner("ğŸ”„ ë°ì´í„°ë¥¼ ë¡œë”©í•˜ê³  ìµœì í™”í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."): df = data_loader.load_from_database()
    if df.empty: st.error("ğŸ˜• ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return

    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.markdown('<div style="text-align: center; padding: 1rem; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; margin-bottom: 1rem; color: white;"><h2>ğŸš€ ê°“ìƒë¼ì´í”„</h2><p style="margin: 0; opacity: 0.9;">AI ê¸°ë°˜ ì„±ì¥í˜• ì±„ìš©</p></div>', unsafe_allow_html=True)
        st.header("ğŸ‘¤ ê°œì¸ í”„ë¡œí•„"); user_skills_input = st.text_area("ë³´ìœ  ê¸°ìˆ  ìŠ¤íƒ (ì‰¼í‘œë¡œ êµ¬ë¶„)", placeholder="Python, React, AWS")
        with st.expander("ğŸ“ˆ ì„±ì¥ í”„ë¡œí•„ (ì„ íƒ)"): recent_courses = st.number_input("ìµœê·¼ 1ë…„ ìˆ˜ê°• ê°•ì˜ ìˆ˜", 0, 50, 0); project_count = st.number_input("ê°œì¸/íŒ€ í”„ë¡œì íŠ¸ ìˆ˜", 0, 20, 0); github_contributions = st.number_input("GitHub ì—°ê°„ ê¸°ì—¬ë„", 0, 1000, 0)
        user_profile = {'skills': [s.strip() for s in user_skills_input.split(',') if s.strip()], 'recent_courses': recent_courses, 'project_count': project_count, 'github_contributions': github_contributions}
        st.markdown("---"); st.header("ğŸ” ìŠ¤ë§ˆíŠ¸ í•„í„°"); filter_conditions = {'user_category': st.selectbox("ê´€ì‹¬ ì§ë¬´", ['ì „ì²´'] + sorted(list(df['job_category'].dropna().unique()))), 'selected_region': st.selectbox("ğŸ“ ê·¼ë¬´ ì§€ì—­", ['ì „ì²´'] + sorted(list(df['address_region'].dropna().unique()))), 'keyword_input': st.text_input("ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰")}
        if st.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"): st.cache_data.clear(); st.rerun()
    
    # í•„í„° ì ìš© ë° ìš”ì•½
    filtered_df = apply_filters(df, filter_conditions, user_profile)
    active_filters = [f"**{k.replace('_', ' ').title()}:** `{v}`" for k, v in filter_conditions.items() if v and (isinstance(v, str) and v != 'ì „ì²´')]
    st.markdown(f'<div class="alert-success">ğŸ” <strong>ì ìš©ëœ í•„í„°:</strong> {(" | ".join(active_filters)) if active_filters else "ì „ì²´"} | <strong>ê²°ê³¼:</strong> {len(filtered_df):,}ê°œ ê³µê³ </div>', unsafe_allow_html=True)
    
    # íƒ­ êµ¬ì„±
    tabs = st.tabs(["â­ ë©”ì¸ ëŒ€ì‹œë³´ë“œ", "ğŸ¯ AI ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­", "ğŸ“ˆ ê°œì¸ ì„±ì¥ ê²½ë¡œ", "ğŸ“Š ì‹œì¥ íŠ¸ë Œë“œ", "ğŸ¢ ê¸°ì—… ì¸ì‚¬ì´íŠ¸", "ğŸ”® ì˜ˆì¸¡ ë¶„ì„", "ğŸ“‹ ìƒì„¸ ë°ì´í„°"])
    with tabs[0]: render_enhanced_main_summary(df)
    with tabs[1]: render_enhanced_smart_matching(filtered_df, user_profile, matching_engine, df)
    with tabs[2]: render_advanced_growth_path(df, user_profile, filter_conditions['user_category'], matching_engine)
    with tabs[3]: render_market_trend_dashboard(df)
    # ... (ë‹¤ë¥¸ íƒ­ ë Œë”ë§ í•¨ìˆ˜ í˜¸ì¶œ)
    
if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        st.error(f"ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        logger.error(f"Application error: {e}", exc_info=True)
