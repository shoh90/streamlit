# app.py - Rallit ìŠ¤ë§ˆíŠ¸ ì±„ìš© ëŒ€ì‹œë³´ë“œ (ìµœì¢… ì™„ì„±ë³¸, êµ¬ë¬¸ ì˜¤ë¥˜ ìˆ˜ì •)

import streamlit as st
import pandas as pd
import sqlite3
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
from pathlib import Path
import logging
import random
import re
import requests
import xml.etree.ElementTree as ET
import folium
from streamlit_folium import st_folium

# ==============================================================================
# 1. í˜ì´ì§€ ë° í™˜ê²½ ì„¤ì •
# ==============================================================================
st.set_page_config(
    page_title="Rallit ìŠ¤ë§ˆíŠ¸ ì±„ìš© ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ==============================================================================
# 2. ì»¤ìŠ¤í…€ CSS
# ==============================================================================
st.markdown("""
<style>
    .problem-card { background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); padding: 1.5rem; border-radius: 15px; color: white; margin: 0.5rem 0; box-shadow: 0 8px 32px rgba(31, 38, 135, 0.37); min-height: 180px; }
    .skill-match { display: inline-block; background: #e8f5e8; padding: 0.3rem 0.6rem; border-radius: 15px; border: 1px solid #4caf50; margin: 0.2rem; font-size: 0.9em; color: #145a32; }
    .skill-gap { display: inline-block; background: #fff3e0; padding: 0.3rem 0.6rem; border-radius: 15px; border: 1px solid #ff9800; margin: 0.2rem; font-size: 0.9em; color: #9c5400;}
    .growth-indicator { background: linear-gradient(90deg, #a8edea 0%, #fed6e3 100%); padding: 0.8rem; border-radius: 10px; margin: 0.5rem 0; }
    h3 { padding-bottom: 10px; }
</style>
""", unsafe_allow_html=True)


# ==============================================================================
# 3. í•µì‹¬ í´ë˜ìŠ¤ ì •ì˜
# ==============================================================================
class SmartDataLoader:
    def __init__(self, db_path='rallit_jobs.db', data_dir='data'):
        self.db_path = db_path; self.data_dir = Path(data_dir)
        self.csv_files = {'MANAGEMENT': 'rallit_management_jobs.csv', 'MARKETING': 'rallit_marketing_jobs.csv', 'DESIGN': 'rallit_design_jobs.csv', 'DEVELOPER': 'rallit_developer_jobs.csv'}
    @st.cache_data
    def load_from_database(_self):
        try:
            if not Path(_self.db_path).exists(): _self._create_database_from_csv()
            conn = sqlite3.connect(_self.db_path); df = pd.read_sql_query("SELECT * FROM jobs", conn); conn.close()
            for col in ['join_reward', 'is_partner', 'is_bookmarked']:
                if col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
            return df
        except Exception: return _self._load_from_csv_fallback()
    def _load_from_csv_fallback(self):
        try:
            dfs = [pd.read_csv(self.data_dir / f).assign(job_category=cat) for cat, f in self.csv_files.items() if (self.data_dir / f).exists()]
            if not dfs: return self._load_sample_data()
            df = pd.concat(dfs, ignore_index=True)
            df.columns = [c.lower().replace(' ', '_').replace('.', '_') for c in df.columns]
            for col in ['join_reward', 'is_partner', 'is_bookmarked']:
                if col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
            return df
        except Exception: return self._load_sample_data()
    def _create_database_from_csv(self):
        df = self._load_from_csv_fallback()
        if not df.empty: conn = sqlite3.connect(self.db_path); df.to_sql('jobs', conn, if_exists='replace', index=False); conn.close()
    def _load_sample_data(self):
        st.warning("ğŸ“ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ìƒ˜í”Œ ë°ì´í„°ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."); categories = ['DEVELOPER', 'DESIGN', 'MARKETING', 'MANAGEMENT']; regions = ['PANGYO', 'GANGNAM', 'HONGDAE', 'JONGNO']; companies = ['í…Œí¬ì»´í¼ë‹ˆA', 'ìŠ¤íƒ€íŠ¸ì—…B', 'ëŒ€ê¸°ì—…C', 'AIìŠ¤íƒ€íŠ¸ì—…G']; skills = {'DEVELOPER': ['Python', 'JavaScript', 'React', 'Node.js', 'Java', 'Docker', 'AWS'], 'DESIGN': ['Figma', 'Sketch', 'Adobe XD', 'Zeplin'], 'MARKETING': ['Google Analytics', 'SEO', 'Content Marketing'], 'MANAGEMENT': ['Project Management', 'Agile', 'Scrum']}; data = []
        for i in range(150): cat = random.choice(categories); data.append({'id': i, 'job_category': cat, 'address_region': random.choice(regions), 'company_name': random.choice(companies), 'title': f'{cat.title()} ì±„ìš© - {random.choice(companies)}', 'status_name': random.choice(['ëª¨ì§‘ ì¤‘', 'ë§ˆê°']), 'status_code': 'HIRING', 'is_partner': random.choice([0, 1]), 'is_bookmarked': 0, 'join_reward': random.choice([0, 50000, 100000, 200000, 500000]), 'job_skill_keywords': ','.join(random.sample(skills[cat], k=random.randint(2, 4))), 'job_level': random.choice(['JUNIOR', 'SENIOR', 'LEAD', 'IRRELEVANT']), 'created_at': datetime.now()})
        return pd.DataFrame(data)

class SmartMatchingEngine:
    def calculate_skill_match(self, user_skills, job_requirements):
        if not user_skills or not job_requirements or not isinstance(job_requirements, str): return 0, [], []
        user_skills_set = {s.strip().lower() for s in user_skills if s.strip()}; job_skills_set = {s.strip().lower() for s in job_requirements.split(',') if s.strip()}
        if not job_skills_set: return 0, [], []
        intersection = user_skills_set.intersection(job_skills_set); match_score = (len(intersection) / len(job_skills_set)) * 100 if job_skills_set else 0
        return match_score, list(intersection), list(job_skills_set - user_skills_set)
    def analyze_growth_potential(self, user_profile):
        score, factors = 0, []; modern_skills = ['ai', 'ml', 'docker', 'kubernetes', 'react', 'vue', 'typescript']; user_skills_lower = [s.lower() for s in user_profile.get('skills', [])]
        if user_profile.get('recent_courses', 0) > 0: score += 20; factors.append(f"ìµœê·¼ í•™ìŠµ ({user_profile.get('recent_courses')}ê°œ)")
        if user_profile.get('project_count', 0) > 3: score += 25; factors.append(f"í”„ë¡œì íŠ¸ ê²½í—˜ ({user_profile.get('project_count')}ê°œ)")
        if len(user_profile.get('skills', [])) > 8: score += 20; factors.append(f"ê¸°ìˆ  ìŠ¤íƒ ë‹¤ì–‘ì„± ({len(user_profile.get('skills', []))}ê°œ)")
        if user_profile.get('github_contributions', 0) > 100: score += 15; factors.append(f"ì˜¤í”ˆì†ŒìŠ¤ ê¸°ì—¬ ({user_profile.get('github_contributions')}íšŒ)")
        if any(skill in modern_skills for skill in user_skills_lower): score += 20; factors.append("ìµœì‹  ê¸°ìˆ  íŠ¸ë Œë“œ ê´€ì‹¬")
        return min(score, 100), factors
    def predict_success_probability(self, skill_score, growth_score):
        return round((skill_score * 0.7 + growth_score * 0.3), 1)


# ==============================================================================
# 4. ë·° í•¨ìˆ˜ ì •ì˜
# ==============================================================================

# <<< ì˜¤ë¥˜ ìˆ˜ì •: ëª¨ë“  ë·° í•¨ìˆ˜ì˜ ì „ì²´ ë‚´ìš©ì„ ë³µì› >>>
def render_smart_matching(filtered_df, user_profile, matching_engine, all_df):
    st.header("ğŸ¯ ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­ ê²°ê³¼")
    if not user_profile['skills']: st.info("ğŸ‘† ì‚¬ì´ë“œë°”ì— ë³´ìœ  ê¸°ìˆ ì„ ì…ë ¥í•˜ë©´ ë§ì¶¤ ê³µê³ ë¥¼ ì¶”ì²œí•´ ë“œë¦½ë‹ˆë‹¤."); return

    growth_score, _ = matching_engine.analyze_growth_potential(user_profile)
    
    match_results = []
    for idx, row in filtered_df.iterrows():
        skill_score, matched, missing = matching_engine.calculate_skill_match(user_profile['skills'], row.get('job_skill_keywords'))
        if skill_score > 20:
            success_prob = matching_engine.predict_success_probability(skill_score, growth_score)
            match_results.append({'idx': idx, 'title': row['title'], 'company': row['company_name'], 'skill_score': skill_score, 'success_prob': success_prob, 'matched': matched, 'missing': missing})

    st.subheader(f"ğŸŒŸ '{', '.join(user_profile['skills'])}' ìŠ¤í‚¬ê³¼ ë§ëŠ” ì¶”ì²œ ê³µê³ ")
    if not match_results:
        st.warning("ì•„ì‰½ì§€ë§Œ, í˜„ì¬ í•„í„° ì¡°ê±´ì— ë§ëŠ” ì¶”ì²œ ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ë³´ì„¸ìš”.")
        with st.expander("ğŸ¤” í˜¹ì‹œ ì´ëŸ° ê±´ ì–´ë– ì„¸ìš”? (ëŒ€ì•ˆ ì œì•ˆ ê¸°ëŠ¥)"):
            st.markdown("**ë‹¤ë¥¸ ì§ë¬´ ì°¾ì•„ë³´ê¸°**"); current_category = filtered_df['job_category'].iloc[0] if not filtered_df.empty else None
            other_categories = [cat for cat in all_df['job_category'].unique() if cat != current_category]
            if other_categories: st.write(f"í˜„ì¬ ì§ë¬´ ì™¸ì—ë„ ì´ëŸ° ì§ë¬´ë“¤ì´ ìˆìŠµë‹ˆë‹¤: `{'`, `'.join(other_categories[:3])}`")
            st.markdown("**ì¸ì ‘ ê¸°ìˆ  ìŠ¤íƒ í•™ìŠµí•˜ê¸°**"); adjacent_skills = {'React': 'Vue.js', 'Python': 'Go', 'AWS': 'GCP, Azure', 'Docker': 'Kubernetes'}
            suggestions = [f"`{v}`" for k, v in adjacent_skills.items() if k.lower() in [s.lower() for s in user_profile['skills']]]
            if suggestions: st.write(f"í˜„ì¬ ë³´ìœ  ìŠ¤í‚¬ ê¸°ë°˜ìœ¼ë¡œ ì´ëŸ° ê¸°ìˆ ì„ ì¶”ê°€ í•™ìŠµí•˜ë©´ ì¢‹ìŠµë‹ˆë‹¤: {', '.join(suggestions)}")
        return

    for i, res in enumerate(sorted(match_results, key=lambda x: x['success_prob'], reverse=True)[:5]):
        with st.expander(f"ğŸ† #{i+1} {res['title']} - ìµœì¢… í•©ê²© í™•ë¥ : {res['success_prob']}%"):
            c1, c2 = st.columns([2, 1]);
            with c1:
                st.write(f"**íšŒì‚¬:** {res['company']}")
                st.metric(label="JD-ìŠ¤í™ ë§¤ì¹­ë„", value=f"{res['skill_score']:.1f}%")
                if res['matched']: st.markdown("**ğŸ¯ ë³´ìœ  ìŠ¤í‚¬ ë§¤ì¹˜:**" + "".join([f'<div class="skill-match">âœ… {s.capitalize()}</div>' for s in res['matched']]), unsafe_allow_html=True)
                if res['missing']: st.markdown("**ğŸ“š ì¶”ê°€ í•™ìŠµ í•„ìš”:**" + "".join([f'<div class="skill-gap">ğŸ“– {s.capitalize()}</div>' for s in res['missing'][:3]]), unsafe_allow_html=True)
            with c2:
                fig = go.Figure(go.Indicator(mode="gauge+number", value=res['success_prob'], title={'text': "ìµœì¢… í•©ê²© í™•ë¥ "}, domain={'x': [0, 1], 'y': [0, 1]}, gauge={'axis': {'range': [None, 100]}, 'bar': {'color': "#667eea"}}))
                fig.update_layout(height=200, margin=dict(l=20, r=20, t=40, b=20)); st.plotly_chart(fig, use_container_width=True, key=f"match_gauge_{res['idx']}")

def render_market_analysis(filtered_df):
    st.header("ğŸ“Š ì±„ìš© ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„");
    if filtered_df.empty: st.warning("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ì£¼ì„¸ìš”."); return
    c1, c2 = st.columns(2)
    with c1:
        counts = filtered_df['job_category'].value_counts()
        fig = px.pie(counts, values=counts.values, names=counts.index, title="ì§ë¬´ë³„ ê³µê³  ë¶„í¬", hole=0.4)
        st.plotly_chart(fig, use_container_width=True, key="cat_pie_market")
    with c2:
        counts = filtered_df['address_region'].value_counts().head(10)
        fig = px.bar(counts, y=counts.index, x=counts.values, orientation='h', title="ìƒìœ„ 10ê°œ ì§€ì—­ ì±„ìš© í˜„í™©", labels={'y':'ì§€ì—­', 'x':'ê³µê³  ìˆ˜'})
        fig.update_layout(yaxis={'categoryorder':'total ascending'}); st.plotly_chart(fig, use_container_width=True, key="region_bar_market")
    st.subheader("ğŸ”¥ ì¸ê¸° ê¸°ìˆ  ìŠ¤íƒ íŠ¸ë Œë“œ")
    if 'job_skill_keywords' in filtered_df.columns:
        skills = filtered_df['job_skill_keywords'].dropna().str.split(',').explode().str.strip()
        skill_counts = skills[skills != ''].value_counts().head(15)
        if not skill_counts.empty:
            fig = px.bar(skill_counts, x=skill_counts.values, y=skill_counts.index, orientation='h', title="TOP 15 ì¸ê¸° ê¸°ìˆ ", labels={'y':'ê¸°ìˆ ', 'x':'ì–¸ê¸‰ íšŸìˆ˜'})
            fig.update_layout(yaxis={'categoryorder': 'total ascending'}); st.plotly_chart(fig, use_container_width=True, key="skills_bar_market")

def render_growth_path(df, user_profile, user_category, matching_engine):
    st.header("ğŸ“ˆ ê°œì¸ ì„±ì¥ ê²½ë¡œ ë¶„ì„");
    if not user_profile['skills']: st.info("ğŸ‘† ì‚¬ì´ë“œë°”ì— ë³´ìœ  ê¸°ìˆ ì„ ì…ë ¥í•˜ë©´ ì„±ì¥ ê²½ë¡œë¥¼ ë¶„ì„í•´ ë“œë¦½ë‹ˆë‹¤."); return
    st.subheader("ğŸš€ ë‹¹ì‹ ì˜ ì„±ì¥ ì ì¬ë ¥"); growth_score, factors = matching_engine.analyze_growth_potential(user_profile); c1, c2 = st.columns([1, 2])
    with c1: fig = go.Figure(go.Indicator(mode="gauge+number", value=growth_score, title={'text': "ì„±ì¥ ì ì¬ë ¥"})); st.plotly_chart(fig, use_container_width=True, key="growth_gauge_path")
    with c2:
        st.markdown("**ğŸŒ± ì„±ì¥ ìš”ì¸ ë¶„ì„:**");
        if factors: [st.markdown(f'<div class="growth-indicator">{f}</div>', unsafe_allow_html=True) for f in factors]
        else: st.write("ì„±ì¥ í”„ë¡œí•„ì„ ì…ë ¥í•˜ë©´ ë” ì •í™•í•œ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    st.subheader("ğŸ¯ ìŠ¤í‚¬ ê°­ ë¶„ì„")
    if 'job_skill_keywords' in df.columns:
        target_df = df[df['job_category'] == user_category] if user_category != 'ì „ì²´' else df
        req_skills = target_df['job_skill_keywords'].dropna().str.split(',').explode().str.strip()
        req_counts = req_skills[req_skills != ''].value_counts().head(10)
        if not req_counts.empty:
            user_s_lower = [s.lower() for s in user_profile['skills']]
            gap_data = [{'skill': s, 'demand': c, 'status': 'ë³´ìœ ' if s.lower() in user_s_lower else 'í•™ìŠµ í•„ìš”'} for s, c in req_counts.items()]
            fig = px.bar(pd.DataFrame(gap_data), x='demand', y='skill', color='status', orientation='h', title=f"'{user_category}' ì§ë¬´ í•µì‹¬ ìŠ¤í‚¬ê³¼ ë³´ìœ  í˜„í™©", color_discrete_map={'ë³´ìœ ': '#4caf50', 'í•™ìŠµ í•„ìš”': '#ff9800'})
            fig.update_layout(yaxis={'categoryorder': 'total ascending'}); st.plotly_chart(fig, use_container_width=True, key="skill_gap_bar_path")

def render_company_insight(filtered_df):
    st.header("ğŸ¢ ê¸°ì—…ë³„ ì±„ìš© ë¶„ì„");
    if filtered_df.empty: st.warning("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ì£¼ì„¸ìš”."); return
    top_companies = filtered_df['company_name'].value_counts().head(15)
    fig = px.bar(top_companies, y=top_companies.index, x=top_companies.values, orientation='h', title="ì±„ìš© ê³µê³ ê°€ ë§ì€ ê¸°ì—… TOP 15", labels={'y':'ê¸°ì—…ëª…', 'x':'ê³µê³  ìˆ˜'})
    fig.update_layout(yaxis={'categoryorder':'total ascending'}); st.plotly_chart(fig, use_container_width=True, key="company_bar_insight")

@st.cache_data(ttl=3600)
def fetch_labor_trend_data():
    url = "https://eis.work24.go.kr/opi/joApi.do"
    auth_key = st.secrets.get("EIS_AUTH_KEY", "YOUR_AUTH_KEY_HERE")
    if auth_key == "YOUR_AUTH_KEY_HERE":
        return None, "NO_KEY"
    params = {'authKey': auth_key, 'apiSecd': 'OPIA', 'rernSecd': 'XML', 'display': 100, 'closStdrYm': datetime.now().strftime('%Y%m')}
    try:
        response = requests.get(url, params=params, timeout=10)
        if response.status_code != 200 or '<!DOCTYPE html>' in response.text:
            return None, "API_ERROR"
        root = ET.fromstring(response.text)
        data_list = [{'company': item.findtext('company'), 'title': item.findtext('title'), 'region': item.findtext('region'), 'sal': item.findtext('sal'), 'minEdubg': item.findtext('minEdubg'), 'career': item.findtext('career')} for item in root.findall('.//item')]
        return data_list, "SUCCESS"
    except (requests.exceptions.RequestException, ET.ParseError) as e:
        return None, "REQUEST_FAIL"

def render_labor_trend_analysis():
    st.header("ğŸ’¡ ì‹¤ì‹œê°„ ë…¸ë™ì‹œì¥ íŠ¸ë Œë“œ (ê³ ìš©ë…¸ë™ë¶€ API)")
    with st.spinner("ì‹¤ì‹œê°„ ê³ ìš© ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
        trend_data, status = fetch_labor_trend_data()
    
    if status == "SUCCESS" and trend_data:
        trends_df = pd.DataFrame(trend_data)
        st.subheader("ğŸ—ºï¸ ì§€ë„ ê¸°ë°˜ ì‹¤ì‹œê°„ ì±„ìš© ìˆ˜ìš”")
        location_dict = {"ì„œìš¸": [37.5665, 126.9780], "ë¶€ì‚°": [35.1796, 129.0756], "ëŒ€êµ¬": [35.8714, 128.6014], "ì¸ì²œ": [37.4563, 126.7052], "ê´‘ì£¼": [35.1595, 126.8526], "ëŒ€ì „": [36.3504, 127.3845], "ìš¸ì‚°": [35.5384, 129.3114], "ì„¸ì¢…": [36.4801, 127.2891], "ê²½ê¸°": [37.4138, 127.5183], "ê°•ì›": [37.8228, 128.1555], "ì¶©ë¶": [36.6358, 127.4917], "ì¶©ë‚¨": [36.5184, 126.8000], "ì „ë¶": [35.7167, 127.1442], "ì „ë‚¨": [34.8161, 126.4630], "ê²½ë¶": [36.4919, 128.8889], "ê²½ë‚¨": [35.4606, 128.2132], "ì œì£¼": [33.4996, 126.5312]}
        trends_df['region_simple'] = trends_df['region'].str.split().str[0].str.replace("íŠ¹ë³„ì‹œ", "").str.replace("ê´‘ì—­ì‹œ", "").str.replace("íŠ¹ë³„ìì¹˜ì‹œ", "").str.replace("íŠ¹ë³„ìì¹˜ë„", "")
        region_counts = trends_df['region_simple'].value_counts()
        m = folium.Map(location=[36.5, 127.8], zoom_start=7, tiles="cartodbpositron")
        for region, count in region_counts.items():
            if region in location_dict: folium.CircleMarker(location=location_dict[region], radius=max(5, count), popup=f"{region}: {count}ê±´", color='#3186cc', fill=True, fill_color='#3186cc', fill_opacity=0.6).add_to(m)
        st_folium(m, width=1000, height=400, key="folium_map")
    elif status == "NO_KEY": st.error("ğŸš¨ API ì¸ì¦í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Cloudì˜ Secretsì— `EIS_AUTH_KEY`ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    else: st.warning(f"âš ï¸ ê³ ìš©ë…¸ë™ë¶€ APIì—ì„œ ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (ì˜¤ë¥˜ ì½”ë“œ: {status}). ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

def render_prediction_analysis():
    st.header("ğŸ”® ì˜ˆì¸¡ ë¶„ì„ (Coming Soon!)")
    st.image("https://images.unsplash.com/photo-1531297484001-80022131f5a1?q=80&w=2020&auto=format&fit=crop", caption="AIê°€ ë‹¹ì‹ ì˜ ì»¤ë¦¬ì–´ ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")
    st.subheader("ì¤€ë¹„ ì¤‘ì¸ ê¸°ëŠ¥ë“¤")
    c1, c2 = st.columns(2)
    with c1:
        st.info("**ğŸ“ˆ ë¯¸ë˜ ì±„ìš© ì‹œì¥ ì˜ˆì¸¡**\n\n- ì§ë¬´ë³„/ê¸°ìˆ ë³„ ì±„ìš© ìˆ˜ìš”ê°€ ì–´ë–»ê²Œ ë³€í• ì§€ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")
        st.info("**ğŸ’° ê°œì¸ ì—°ë´‰ ì˜ˆì¸¡**\n\n- ë‚˜ì˜ ìŠ¤í™ê³¼ ê²½ë ¥ìœ¼ë¡œ ì–´ëŠ ì •ë„ì˜ ì—°ë´‰ì„ ë°›ì„ ìˆ˜ ìˆëŠ”ì§€ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")
    with c2:
        st.info("**ğŸŒ± ê¸°ìˆ  ì„±ì¥ë¥  ì˜ˆì¸¡**\n\n- ì–´ë–¤ ê¸°ìˆ ì´ ë¯¸ë˜ì— ìœ ë§í• ì§€ ì„±ì¥ë¥ ì„ ì˜ˆì¸¡í•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤.")
        st.info("**ğŸ¢ ê¸°ì—… ë¬¸í™” ì í•©ë„ ì˜ˆì¸¡**\n\n- ë‚˜ì˜ ì„±í–¥ê³¼ ê°€ì¥ ì˜ ë§ëŠ” ê¸°ì—… ë¬¸í™”ë¥¼ ì°¾ì•„ ì¶”ì²œí•©ë‹ˆë‹¤.")

def render_detail_table(filtered_df):
    st.header("ğŸ“‹ ìƒì„¸ ë°ì´í„°");
    if filtered_df.empty: st.warning("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ì£¼ì„¸ìš”."); return
    st.dataframe(filtered_df, use_container_width=True, height=600)
    csv = filtered_df.to_csv(index=False).encode('utf-8-sig')
    st.download_button("ğŸ“„ CSV ë‹¤ìš´ë¡œë“œ", csv, "rallit_jobs_filtered.csv", "text/csv")


# ==============================================================================
# 5. ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
# ==============================================================================
def main():
    st.title("Rallit ìŠ¤ë§ˆíŠ¸ ì±„ìš© ëŒ€ì‹œë³´ë“œ")
    with st.expander("âœ¨ ëŒ€ì‹œë³´ë“œ ê¸°íš ì˜ë„ ìì„¸íˆ ë³´ê¸°"):
        st.markdown("## ğŸ¯ í•´ê²°í•˜ê³ ì í•˜ëŠ” ë¬¸ì œë“¤")
        c1,c2,c3 = st.columns(3); c1.markdown('<div class="problem-card"><h3>ğŸ‘¤ êµ¬ì§ì ë¬¸ì œ</h3><ul><li>ì í•©í•œ ê³µê³  ì°¾ê¸° ì–´ë ¤ì›€</li><li>JD-ìŠ¤í™ ë¯¸ìŠ¤ë§¤ì¹­</li><li>ì„±ì¥ê³¼ì • í‰ê°€ ë¶€ì¡±</li></ul></div>', unsafe_allow_html=True); c2.markdown('<div class="problem-card"><h3>ğŸ¢ ê¸°ì—… ë¬¸ì œ</h3><ul><li>ì‹¤ë¬´ì—­ëŸ‰ íŒë‹¨ ì–´ë ¤ì›€</li><li>ì •ëŸ‰ì  ê¸°ì¤€ ë¶€ì¡±</li><li>ì„±ê³¼ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥</li></ul></div>', unsafe_allow_html=True); c3.markdown('<div class="problem-card"><h3>ğŸ”§ í”Œë«í¼ ë¬¸ì œ</h3><ul><li>ì„±ì¥ì—¬ì • ë¯¸ë°˜ì˜</li><li>ë‹¨ìˆœ í‚¤ì›Œë“œ ë§¤ì¹­</li><li>ìµœì‹  íŠ¸ë Œë“œ ë¶€ì¡±</li></ul></div>', unsafe_allow_html=True)
    st.markdown("---")
    
    data_loader = SmartDataLoader(); matching_engine = SmartMatchingEngine(); df = data_loader.load_from_database()
    if df.empty: st.error("ğŸ˜• ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return

    with st.sidebar:
        st.header("ğŸ¯ ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­ í”„ë¡œí•„"); user_skills_input = st.text_area("ë³´ìœ  ê¸°ìˆ  ìŠ¤íƒ (ì‰¼í‘œë¡œ êµ¬ë¶„)", placeholder="ì˜ˆ: Python, React, AWS")
        with st.expander("ğŸ“ˆ ì„±ì¥ í”„ë¡œí•„ (ì„ íƒ)"): recent_courses = st.number_input("ìµœê·¼ 1ë…„ ìˆ˜ê°• ê°•ì˜ ìˆ˜", 0, 50, 0); project_count = st.number_input("ê°œì¸/íŒ€ í”„ë¡œì íŠ¸ ìˆ˜", 0, 20, 0); github_contributions = st.number_input("GitHub ì—°ê°„ ê¸°ì—¬ë„", 0, 1000, 0)
        user_profile = {'skills': [s.strip() for s in user_skills_input.split(',') if s.strip()], 'recent_courses': recent_courses, 'project_count': project_count, 'github_contributions': github_contributions}
        
        st.markdown("---"); st.header("ğŸ” ê³ ê¸‰ í•„í„°"); user_category = st.selectbox("ê´€ì‹¬ ì§ë¬´", ['ì „ì²´'] + sorted(list(df['job_category'].dropna().unique()))); selected_region = st.selectbox("ğŸ“ ê·¼ë¬´ ì§€ì—­", ['ì „ì²´'] + sorted(list(df['address_region'].dropna().unique())))
        reward_filter = st.checkbox("ğŸ’° ì§€ì›ê¸ˆ ìˆëŠ” ê³µê³ ë§Œ ë³´ê¸°"); partner_filter = st.checkbox("ğŸ¤ íŒŒíŠ¸ë„ˆ ê¸°ì—…ë§Œ ë³´ê¸°")
        min_r, max_r = int(df['join_reward'].min()), int(df['join_reward'].max()); join_reward_range = st.slider("ğŸ’µ ì§€ì›ê¸ˆ ë²”ìœ„ (ì›)", min_r, max_r, (min_r, max_r))
        selected_levels = st.multiselect("ğŸ“ˆ ì§ë¬´ ë ˆë²¨", df['job_level'].dropna().unique(), default=list(df['job_level'].dropna().unique())); keyword_input = st.text_input("ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰ (ê³µê³ ëª…/íšŒì‚¬ëª…)", "")
        if st.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"): st.cache_data.clear(); st.rerun()

    filtered_df = df.copy()
    if user_category != 'ì „ì²´': filtered_df = filtered_df[filtered_df['job_category'] == user_category]
    if selected_region != 'ì „ì²´': filtered_df = filtered_df[filtered_df['address_region'] == selected_region]
    if reward_filter: filtered_df = filtered_df[filtered_df['join_reward'] > 0]
    if partner_filter: filtered_df = filtered_df[filtered_df['is_partner'] == 1]
    if selected_levels: filtered_df = filtered_df[filtered_df['job_level'].isin(selected_levels)]
    filtered_df = filtered_df[filtered_df['join_reward'].between(join_reward_range[0], join_reward_range[1])]
    if keyword_input:
        keyword = keyword_input.lower()
        mask = (filtered_df['title'].str.lower().str.contains(keyword, na=False)) | (filtered_df['company_name'].str.lower().str.contains(keyword, na=False))
        filtered_df = filtered_df[mask]
    if user_profile['skills'] and 'job_skill_keywords' in filtered_df.columns:
        user_skills_pattern = '|'.join([re.escape(skill.strip()) for skill in user_profile['skills']])
        filtered_df = filtered_df[filtered_df['job_skill_keywords'].str.contains(user_skills_pattern, case=False, na=False)]

    summary_list = [f"**ë³´ìœ  ìŠ¤í‚¬:** `{', '.join(user_profile['skills'])}`" if user_profile['skills'] else '', f"**ì§ë¬´:** `{user_category}`" if user_category != 'ì „ì²´' else '', f"**ì§€ì—­:** `{selected_region}`" if selected_region != 'ì „ì²´' else '', f"**í‚¤ì›Œë“œ:** `{keyword_input}`" if keyword_input else '']
    active_filters = " | ".join(filter(None, summary_list))
    st.success(f"ğŸ” **í•„í„° ìš”ì•½:** {active_filters if active_filters else 'ì „ì²´ ì¡°ê±´'} | **ê²°ê³¼:** `{len(filtered_df)}`ê°œì˜ ê³µê³ ")

    tabs = st.tabs(["ğŸ¯ ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­", "ğŸ“Š ì‹œì¥ ë¶„ì„", "ğŸ’¡ ë…¸ë™ì‹œì¥ íŠ¸ë Œë“œ", "ğŸ“ˆ ì„±ì¥ ê²½ë¡œ", "ğŸ¢ ê¸°ì—… ì¸ì‚¬ì´íŠ¸", "ğŸ”® ì˜ˆì¸¡ ë¶„ì„", "ğŸ“‹ ìƒì„¸ ë°ì´í„°"])
    with tabs[0]: render_smart_matching(filtered_df, user_profile, matching_engine, df)
    with tabs[1]: render_market_analysis(filtered_df)
    with tabs[2]: render_labor_trend_analysis()
    with tabs[3]: render_growth_path(df, user_profile, user_category, matching_engine)
    with tabs[4]: render_company_insight(filtered_df)
    with tabs[5]: render_prediction_analysis()
    with tabs[6]: render_detail_table(filtered_df)

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        st.error(f"ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"); logger.error(f"Application error: {e}", exc_info=True)
